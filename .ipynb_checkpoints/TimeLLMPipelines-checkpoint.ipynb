{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc834ae8-0aaf-45d6-82d6-e212638c4c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models import TimeLLM\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc15111-5a4f-4a74-9b1b-354285f1bfde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ce3ea-6884-4373-a22e-61f095b6efe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8ade4-f379-4ead-927c-27c609ae0869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6308f-6ee1-4b8f-9fc5-fa7a56994d50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FixedModelTimeLLMProcessor():\n",
    "    def __init__(self, overall_df, dates):\n",
    "        self.overall_df = overall_df\n",
    "        self.overall_df_value_col = \"value\"\n",
    "        self.dates = dates\n",
    "        self.dfs = []\n",
    "        \n",
    "        self.nf = None\n",
    "        \n",
    "        self.forecasts = []\n",
    "        self.plotting_df = pd.DataFrame()\n",
    "        \n",
    "        self.maes = []\n",
    "        self.mses = []\n",
    "        self.mapes = []\n",
    "        self.nmses = []\n",
    "        \n",
    "        self.metrics_df = pd.DataFrame(columns = [\"Reference Date\", \"MAE\", \"MSE\", \"MAPE\", \"NMSE\"])\n",
    "        self.display_df = pd.DataFrame(columns = [\"Reference Date\", \"Target End Date\", \"Quantile\", \"Prediction\"])\n",
    "        \n",
    "        self.color_mapping = {}\n",
    "        \n",
    "        \n",
    "        self.llm_config = AutoConfig.from_pretrained(\"distilgpt2\")\n",
    "        self.llm_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "    \n",
    "    def create_training_dfs(self, value_col):\n",
    "        self.overall_df_value_col = value_col\n",
    "        for date in self.dates:\n",
    "            df = self.overall_df.loc[:date]\n",
    "            df['ds'] = df.index\n",
    "            df[\"unique_id\"] = \"series_1\"\n",
    "            df = df.rename(columns = {value_col: \"y\"})\n",
    "            self.dfs.append(df)\n",
    "    \n",
    "    def create_fixed_model(self, h, freq, model_name, prompt):\n",
    "        if not self.nf:\n",
    "            self.nf = NeuralForecast(models = [TimeLLM(h = h, input_size = 50, llm = 'openai-community/gpt2', \n",
    "                                                       prompt_prefix = prompt, \n",
    "                                                       batch_size = 1, windows_batch_size = 32, inference_windows_batch_size = 32\n",
    "                                                      )], freq = freq)\n",
    "            self.nf.fit(df = self.dfs[0])\n",
    "            self.nf.save(path=f'TimeLLM/fixed_models/{model_name}/', overwrite=True)\n",
    "        \n",
    "        for i in range(len(self.dfs)):\n",
    "            df = self.dfs[i]\n",
    "            y_hat = self.nf.predict(df = df)\n",
    "\n",
    "            y_hat.set_index(\"ds\", inplace = True)\n",
    "            y_hat.drop(columns = \"unique_id\", inplace = True)\n",
    "            self.forecasts.append(y_hat)\n",
    "        \n",
    "\n",
    "    def load_fixed_model(self, path):\n",
    "        self.nf = NeuralForecast.load(path = path)\n",
    "\n",
    "    def create_graph(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(x = self.overall_df.index, y = self.overall_df[self.overall_df_value_col], mode = \"lines\", name = \"Real Data\"))\n",
    "            fig.add_trace(go.Scatter(x = self.forecasts[i].index, y = self.forecasts[i][\"TimeLLM\"], mode = \"lines\", name = \"TimeLLM\"))\n",
    "            fig.update_layout(title = f\"Fixed Parameter TimeLLM Predictions, {self.dates[i]}\", xaxis_title = \"Date\", yaxis_title = \"Count\", hovermode = \"x\")\n",
    "            fig.show()\n",
    "    \n",
    "    def calculate_metrics(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            mae = mean_absolute_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            mse = mean_squared_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            mape = mean_absolute_percentage_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            nmse = mse/np.var(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index])\n",
    "            \n",
    "            self.maes.append(mae)\n",
    "            self.mses.append(mse)\n",
    "            self.mapes.append(mape)\n",
    "            self.nmses.append(nmse)\n",
    "            \n",
    "    def create_metrics_df(self):\n",
    "        for i in range(len(self.dates)):\n",
    "            self.metrics_df.loc[len(self.metrics_df)] = [self.dates[i], self.maes[i], self.mses[i], self.mapes[i], self.nmses[i]]\n",
    "    \n",
    "    def create_display_df(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            for index, row in self.forecasts[i].iterrows():\n",
    "                reference_date = self.dates[i]\n",
    "                target_end_date = index\n",
    "                value = self.forecasts[i].loc[target_end_date, \"TimeLLM\"]\n",
    "                self.display_df.loc[len(self.display_df)] = [reference_date, target_end_date, 0.5, value]\n",
    "        \n",
    "        \n",
    "        self.display_df.sort_values(by = [\"Reference Date\", \"Target End Date\", \"Quantile\"], inplace = True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb3561-ad34-4e31-bf25-1bf9bc64d805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_df = pd.read_csv(\"https://raw.githubusercontent.com/cdcepi/FluSight-forecast-hub/refs/heads/main/target-data/target-hospital-admissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb820d-9ac8-4688-bdc8-a55ae0b5f691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_df = updated_df[updated_df[\"location_name\"] == \"US\"]\n",
    "updated_df = updated_df[[\"date\", \"value\"]]\n",
    "updated_df[\"date\"] = pd.to_datetime(updated_df[\"date\"])\n",
    "updated_df.set_index(\"date\", inplace = True)\n",
    "updated_df.sort_values(by = \"date\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1f793-86be-4786-bce4-8b3077fd832f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor = FixedModelTimeLLMProcessor(overall_df = updated_df, dates = [\"2024-10-05\", \"2024-10-19\", \"2024-11-02\", \"2024-11-16\", \"2024-12-07\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a579026-e7ec-4d08-8610-84397c12b384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_training_dfs(value_col = \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23438cd-0b1d-432f-b246-e6c8430100a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"This dataset contains data on weekly flu hospitalizations in the United States. There is a yearly (52 weeks) seasonality\"\n",
    "Processor.create_fixed_model(h = 4, freq = \"W-SAT\", model_name = \"test_model\", prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae4ca8-1873-4a4b-9b15-bbd93f6447e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Processor.dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2163a45-1dba-4e01-836e-0992ffa56c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a816f5-3700-47ae-aa46-f218daa5769e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(Processor.forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a84614-df6b-4992-8cbd-e5eb6970f8b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.forecasts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a353cf-f640-47e2-ad20-d047d125ecc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d167e4bb-afad-4c2a-87da-0405c26a11d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44887d76-b2e7-4c9e-b79c-0889123f7d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.calculate_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65317128-d432-4e06-9260-303665dd4ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_metrics_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b50621-868d-462a-ba4e-9658c4af79fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb58d01-0425-473f-b432-dd16587bf637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_display_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3edd993-2347-4baa-85c4-67351f86981e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e1268-2820-4b64-bdf8-f0cbaca55e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d58a6-0dbc-47d7-91b8-31f5a1103668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a1f09-c6d8-42b5-a7ab-6c43f2f94266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e456d54-6d9e-449d-b143-f7624754c265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca3c7b-9e59-4f8e-ad20-03855269dde6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb3b7c-d0d2-4e12-88d2-2f3d9d18e5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UpdatingModelTimeLLMProcessor:\n",
    "    def __init__(self, overall_df, dates):\n",
    "        self.overall_df = overall_df\n",
    "        self.overall_df_value_col = \"value\"\n",
    "        self.dates = dates\n",
    "        self.dfs = []\n",
    "        \n",
    "        self.nfs = []\n",
    "        \n",
    "        self.forecasts = []\n",
    "        self.plotting_df = pd.DataFrame()\n",
    "        \n",
    "        self.maes = []\n",
    "        self.mses = []\n",
    "        self.mapes = []\n",
    "        self.nmses = []\n",
    "        \n",
    "        self.metrics_df = pd.DataFrame(columns = [\"Reference Date\", \"MAE\", \"MSE\", \"MAPE\", \"NMSE\"])\n",
    "        self.display_df = pd.DataFrame(columns = [\"Reference Date\", \"Target End Date\", \"Quantile\", \"Prediction\"])\n",
    "        \n",
    "    def create_training_dfs(self, value_col):\n",
    "        self.overall_df_value_col = value_col\n",
    "        for date in self.dates:\n",
    "            df = self.overall_df.loc[:date]\n",
    "            df['ds'] = df.index\n",
    "            df[\"unique_id\"] = \"series_1\"\n",
    "            df = df.rename(columns = {value_col: \"y\"})\n",
    "            self.dfs.append(df)\n",
    "    \n",
    "    def create_models(self, h, freq, model_names, prompt):\n",
    "        if not self.nfs:\n",
    "            for i in range(len(self.dfs)):\n",
    "                nf = NeuralForecast(models = [TimeLLM(h = h, input_size = 3 * h, llm = 'openai-community/gpt2', \n",
    "                                                       prompt_prefix = prompt, \n",
    "                                                       batch_size = 1, windows_batch_size = 32, inference_windows_batch_size = 32\n",
    "                                                      )], freq = freq)\n",
    "                nf.fit(df = self.dfs[i])\n",
    "                \n",
    "                self.nfs.append(nf)\n",
    "                nf.save(path=f'AutoLSTM/updating_models/{model_names[i]}/', overwrite = True)\n",
    "        \n",
    "        for i in range(len(self.dfs)):\n",
    "            y_hat = self.nfs[i].predict(df = self.dfs[i])\n",
    "            y_hat.set_index(\"ds\", inplace = True)\n",
    "            y_hat.drop(columns = \"unique_id\", inplace = True)\n",
    "            self.forecasts.append(y_hat)\n",
    "    \n",
    "    def load_models(self, paths):\n",
    "        for i in range(len(paths)):\n",
    "            nf = NeuralForecast.load(path = paths[i])\n",
    "            self.nfs.append(nf)\n",
    "    \n",
    "    def create_graph(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(x = self.overall_df.index, y = self.overall_df[self.overall_df_value_col], mode = \"lines\", name = \"Real Data\"))\n",
    "            fig.add_trace(go.Scatter(x = self.forecasts[i].index, y = self.forecasts[i][\"TimeLLM\"], mode = \"lines\", name = \"TimeLLM\"))\n",
    "            fig.update_layout(title = f\"Fixed Parameter TimeLLM Predictions, {self.dates[i]}\", xaxis_title = \"Date\", yaxis_title = \"Count\", hovermode = \"x\")\n",
    "            fig.show()\n",
    "\n",
    "    def calculate_metrics(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            mae = mean_absolute_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            mse = mean_squared_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            mape = mean_absolute_percentage_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            nmse = mse/np.var(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index])\n",
    "            \n",
    "            self.maes.append(mae)\n",
    "            self.mses.append(mse)\n",
    "            self.mapes.append(mape)\n",
    "            self.nmses.append(nmse)\n",
    "            \n",
    "    def create_metrics_df(self):\n",
    "        for i in range(len(self.dates)):\n",
    "            self.metrics_df.loc[len(self.metrics_df)] = [self.dates[i], self.maes[i], self.mses[i], self.mapes[i], self.nmses[i]]\n",
    "    \n",
    "    def create_display_df(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            for index, row in self.forecasts[i].iterrows():\n",
    "                reference_date = self.dates[i]\n",
    "                target_end_date = index\n",
    "                value = self.forecasts[i].loc[target_end_date, \"TimeLLM\"]\n",
    "                self.display_df.loc[len(self.display_df)] = [reference_date, target_end_date, 0.5, value]\n",
    "        \n",
    "        \n",
    "        self.display_df.sort_values(by = [\"Reference Date\", \"Target End Date\", \"Quantile\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a918c61-1ace-4545-b0e2-5be0e1f47454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor = UpdatingModelTimeLLMProcessor(overall_df = updated_df, dates = [\"2024-10-05\", \"2024-10-19\", \"2024-11-02\", \"2024-11-16\", \"2024-12-07\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b5b7d-1795-4f3f-bb1e-7bcbdffd2841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_training_dfs(value_col = \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732a33c-64af-4aa0-b65a-3a8935cc2f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"This dataset contains data on weekly flu hospitalizations in the United States. There is a yearly (52 weeks) seasonality\"\n",
    "UpdatingProcessor.create_models(h = 4, freq = \"W-SAT\", model_names = [\"test_1\", \"test_2\", \"test_3\", \"test_4\", \"test_5\"], prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb2803-0fae-49ae-9489-7a884424780f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c66c1-c2a8-463b-bb7f-ce9c1d3df23c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6dbfed-6351-4f2e-bcf7-b8e6ab2dfab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.calculate_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac3bd8-b208-4e56-919f-975870178fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_metrics_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26de889d-d583-46dc-98c8-2cb5937b15bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ebace-ebdb-4a3b-b4d7-40b7f3a5a74d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_display_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679887a-5d07-4ae5-8efc-494ba914d927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac3d82-b37f-456c-9998-610f099def67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
