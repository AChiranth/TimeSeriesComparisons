{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac7fdec-a1bd-4e31-9f74-6feacf65a01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cufflinks as cf\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "cf.go_offline()\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from neuralforecast.auto import AutoLSTM\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models import LSTM\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16ee56-f111-492b-84fc-b7d0dba876fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f1e94-49de-4759-9b92-ec4b2aae1983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neuralforecast.losses.pytorch import MQLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7639236-2ea4-4865-ab18-50a25f21bfef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NeuralForecast.save?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5218041-870a-476d-a48a-424b1bcaf871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FixedModelLSTMProcessor:\n",
    "    def __init__(self, overall_df, dates):\n",
    "        self.overall_df = overall_df\n",
    "        self.overall_df_value_col = \"value\"\n",
    "        self.dates = dates\n",
    "        self.dfs = []\n",
    "        \n",
    "        self.nf = None\n",
    "        \n",
    "        self.forecasts = []\n",
    "        self.plotting_df = pd.DataFrame()\n",
    "        \n",
    "        self.maes = []\n",
    "        self.mses = []\n",
    "        self.mapes = []\n",
    "        self.nmses = []\n",
    "        \n",
    "        self.metrics_df = pd.DataFrame(columns = [\"Reference Date\", \"MAE\", \"MSE\", \"MAPE\", \"NMSE\"])\n",
    "        self.display_df = pd.DataFrame(columns = [\"Reference Date\", \"Target End Date\", \"Quantile\", \"Prediction\"])\n",
    "        \n",
    "        self.color_mapping = {}\n",
    "    \n",
    "    def create_training_dfs(self, value_col):\n",
    "        self.overall_df_value_col = value_col\n",
    "        for date in self.dates:\n",
    "            df = self.overall_df.loc[:date]\n",
    "            df['ds'] = df.index\n",
    "            df[\"unique_id\"] = \"series_1\"\n",
    "            df = df.rename(columns = {value_col: \"y\"})\n",
    "            self.dfs.append(df)\n",
    "        \n",
    "    \n",
    "    def create_fixed_model(self, h, freq, model_name, level = []):\n",
    "        #Creating AutoLSTM model and predicting with hyperparameter tuning by optuna backend. This is based upon the first training dataframe\n",
    "        \n",
    "        #Checking if model has already been loaded in and fit\n",
    "        if not self.nf:\n",
    "            if not level:\n",
    "                self.nf = NeuralForecast(models = [AutoLSTM(h = h, backend = \"optuna\")], freq = freq)\n",
    "                self.nf.fit(df = self.dfs[0])\n",
    "            else:\n",
    "                self.nf = NeuralForecast(models = [AutoLSTM(h = h, backend = \"optuna\", loss = MQLoss(level = level))], freq = freq)\n",
    "                self.nf.fit(df = self.dfs[0])\n",
    "            \n",
    "            self.nf.save(path=f'AutoLSTM/fixed_models/{model_name}/')\n",
    "\n",
    "        for i in range(len(self.dfs)):\n",
    "            df = self.dfs[i]\n",
    "            y_hat = self.nf.predict(df = df)\n",
    "\n",
    "            y_hat.set_index(\"ds\", inplace = True)\n",
    "            y_hat.drop(columns = \"unique_id\", inplace = True)\n",
    "            self.forecasts.append(y_hat)\n",
    "\n",
    "    \n",
    "    def load_fixed_model(self, path):\n",
    "        self.nf = NeuralForecast.load(path = path)\n",
    "        \n",
    "    def generate_color_map(self, columns, cmap_name = \"viridis\"):\n",
    "        intervals = set()\n",
    "        for col in columns:\n",
    "            if 'median' in col:\n",
    "                continue\n",
    "            parts = col.split('-')\n",
    "            number = parts[-1]\n",
    "            intervals.add(number)\n",
    "        \n",
    "        intervals = sorted(intervals, key=int)\n",
    "        cmap = plt.cm.get_cmap(cmap_name)\n",
    "        \n",
    "        n = len(intervals)\n",
    "        if n > 0:\n",
    "            half = np.linspace(0.2, 0.45, n // 2, endpoint=True)[::-1]  # lower intervals\n",
    "            upper = np.linspace(0.55, 0.8, n - n // 2, endpoint=True)  # higher intervals\n",
    "            sample_points = np.concatenate([half, upper])\n",
    "        else:\n",
    "            sample_points = np.array([])  # just median\n",
    "        \n",
    "        median_value = np.median(sample_points)\n",
    "        \n",
    "        color_mapping = {}\n",
    "        color_mapping['median'] = mcolors.to_hex(cmap(median_value))  # center of the colormap\n",
    "        for interval, point in zip(intervals, sample_points):\n",
    "            color_mapping[interval] = mcolors.to_hex(cmap(point))\n",
    "    \n",
    "        return color_mapping\n",
    "    \n",
    "    def create_graph(self):\n",
    "        \n",
    "        #Create color map for various confidence bands, only if levels are present\n",
    "        if len(self.forecasts[0].columns) != 1:\n",
    "            self.color_mapping = self.generate_color_map(columns = self.forecasts[0].columns)\n",
    "                \n",
    "        \n",
    "        for i in range(len(self.forecasts)):\n",
    "            #Plot the overall Real Data\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(x = self.overall_df.index, y = self.overall_df[self.overall_df_value_col], mode = \"lines\", name = \"Real Data\"))\n",
    "\n",
    "            \n",
    "            for col in self.forecasts[i].columns:\n",
    "                #Plot his first\n",
    "                if \"hi\" in col:\n",
    "                    number = col[-2:]\n",
    "                    fig.add_trace(go.Scatter(x = self.forecasts[i].index, y = self.forecasts[i][col], mode = \"lines\", name = col, \n",
    "                                             line = dict(color = self.color_mapping[number])))\n",
    "            \n",
    "            for col in self.forecasts[i].columns:\n",
    "                #Lows will go to corresponding his\n",
    "                if \"lo\" in col:\n",
    "                    number = col[-2:]\n",
    "                    fig.add_trace(go.Scatter(x = self.forecasts[i].index, y = self.forecasts[i][col], mode = \"lines\", name = col, \n",
    "                                             fill = \"tonexty\", fillcolor = self.color_mapping[number], line = dict(color = self.color_mapping[number])))\n",
    "            \n",
    "            for col in self.forecasts[i].columns:\n",
    "                #Median gets plotted last\n",
    "                if \"median\" in col:\n",
    "                    fig.add_trace(go.Scatter(x = self.forecasts[i].index, y = self.forecasts[i][col], mode = \"lines\", name = col, \n",
    "                                             line = dict(color = self.color_mapping[\"median\"])))\n",
    "            \n",
    "            #Case for if confidence interval not present\n",
    "            for col in self.forecasts[i].columns:\n",
    "                if col == \"AutoLSTM\":\n",
    "                    fig.add_trace(go.Scatter(x = self.forecasts[i].index, y = self.forecasts[i][\"AutoLSTM\"], mode = \"lines\", name = \"AutoLSTM\"))\n",
    "            \n",
    "            \n",
    "            fig.update_layout(title = f\"Fixed Parameter LSTM Predictions, {self.dates[i]}\", xaxis_title = \"Date\", yaxis_title = \"Count\", hovermode = \"x\")\n",
    "            fig.show()\n",
    "            \n",
    "    def calculate_metrics(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            mae = mean_absolute_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            mse = mean_squared_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            mape = mean_absolute_percentage_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            nmse = mse/np.var(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index])\n",
    "            \n",
    "            self.maes.append(mae)\n",
    "            self.mses.append(mse)\n",
    "            self.mapes.append(mape)\n",
    "            self.nmses.append(nmse)\n",
    "    \n",
    "    def display_maes(self):\n",
    "        for i in range(len(self.maes)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Absolute Error for {english_date} model: {self.maes[i]}\")\n",
    "        \n",
    "    def display_mses(self):\n",
    "        for i in range(len(self.mses)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Squared Error for {english_date} model: {self.mses[i]}\")\n",
    "    \n",
    "    def display_mapes(self):\n",
    "        for i in range(len(self.mapes)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Absolute Percentage Error for {english_date} model: {self.mapes[i]}\")\n",
    "    \n",
    "    def display_nmses(self):\n",
    "        for i in range(len(self.nmses)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Normalized Mean Square Error for {english_date} model: {self.nmses[i]}\")\n",
    "    \n",
    "    def create_metrics_df(self):\n",
    "        for i in range(len(self.dates)):\n",
    "            self.metrics_df.loc[len(self.metrics_df)] = [self.dates[i], self.maes[i], self.mses[i], self.mapes[i], self.nmses[i]]\n",
    "        \n",
    "            \n",
    "    def create_display_df(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            for index, row in self.forecasts[i].iterrows():\n",
    "                reference_date = self.dates[i]\n",
    "                target_end_date = index\n",
    "                \n",
    "                for col in self.forecasts[i].columns:\n",
    "                    value = self.forecasts[i].loc[target_end_date, col]\n",
    "                    if \"lo\" in col:\n",
    "                        number = int (col[-2:])\n",
    "                        alpha = 1 - (number / 100)\n",
    "                        quantile = alpha / 2\n",
    "                        self.display_df.loc[len(self.display_df)] = [reference_date, target_end_date, quantile, value]\n",
    "\n",
    "                    if col == \"AutoLSTM\" or \"median\" in col:\n",
    "                        quantile = 0.5\n",
    "                        self.display_df.loc[len(self.display_df)] = [reference_date, target_end_date, quantile, value]\n",
    "\n",
    "                    elif \"hi\" in col:\n",
    "                        number = int (col[-2:])\n",
    "                        alpha = 1 - (number / 100)\n",
    "                        quantile = 1 - (alpha / 2)\n",
    "                        self.display_df.loc[len(self.display_df)] = [reference_date, target_end_date, quantile, value]\n",
    "                \n",
    "        self.display_df.sort_values(by = [\"Reference Date\", \"Target End Date\", \"Quantile\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af5694-c6c4-4a04-9c64-4e4590e0681f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_df = pd.read_csv(\"https://raw.githubusercontent.com/cdcepi/FluSight-forecast-hub/refs/heads/main/target-data/target-hospital-admissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ba56f-2195-457c-a505-1cdb8a1b99f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_df = updated_df[updated_df[\"location_name\"] == \"US\"]\n",
    "updated_df = updated_df[[\"date\", \"value\"]]\n",
    "updated_df[\"date\"] = pd.to_datetime(updated_df[\"date\"])\n",
    "updated_df.set_index(\"date\", inplace = True)\n",
    "updated_df.sort_values(by = \"date\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c1aab4-a5b1-4276-8b0d-bddfb2e31399",
   "metadata": {},
   "outputs": [],
   "source": [
    "Processor = FixedModelLSTMProcessor(overall_df = updated_df, dates = [\"2024-10-05\", \"2024-10-19\", \"2024-11-02\", \"2024-11-16\", \"2024-12-07\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bddc3d7-658b-49e9-885a-e15a02977b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_training_dfs(value_col = \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb46fa9-763b-44ac-a535-c98b7ebc5535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_fixed_model(h = 4, freq = \"W-SAT\", model_name = \"test_model\", level = [80, 95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846a64c-4fcf-4473-a2aa-9bae7a224652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(Processor.forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa42b8-67e0-4800-9e36-fe5c37484705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246236a-2ea1-446c-9e1e-6922afc037de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.color_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6257d1e-4ecd-4600-9d26-2c5c265e8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "Processor.calculate_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd11a4-68cd-42f5-a817-85182eca7b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f83c6f-7c92-4e47-8695-83f3a9804cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2bfed-182e-4e27-91e9-4d6a8b4f8226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.mapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c64886-a4b5-4bbe-80fe-60ba5f79caa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_display_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680da260-4656-47e6-b153-bd335be097ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa4533-8feb-4065-84d1-84abebc9ae93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_metrics_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bdb5ad-2bf1-4c53-b9ab-687d506e95f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa836c-4f69-4929-b34d-ed24b4087651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114e237-5fc7-4db7-bf3a-9960b4f38ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor2 = FixedModelLSTMProcessor(overall_df = updated_df, dates = [\"2024-10-05\", \"2024-10-19\", \"2024-11-02\", \"2024-11-16\", \"2024-12-07\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228238f9-bc47-42dc-b089-46454275cc63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor2.create_training_dfs(value_col=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8590f-22d7-4ed9-9c2e-9719f13d4a82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor2.load_fixed_model(path = \"AutoLSTM/fixed_models/test_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082ed40-f9be-4e74-9732-2776fbf84a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor2.create_fixed_model(h = 4, freq = \"W-SAT\", model_name = \"test_model\", level = [80, 95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c8a8b-2a5c-42a4-88ad-b8d6079af350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor2.create_display_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3324b9c-7f26-467b-b4a4-52599d625652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.display_df.equals(Processor2.display_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675eb52c-6f49-45d3-b639-50dfaa3f9c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9c3e6-d563-40ba-8250-aad04d99ff7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a72f0-34a6-4e80-a3f8-d934bb5a1668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937a7ec-cd70-4e1f-9e0e-5e8208004ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9cea2d-33af-4a9c-ba2a-31e36a73e989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d653d87-211c-4143-85b0-9a5175083544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf71b60-1099-40ab-824d-24ed68b10de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0803a22-783e-4bde-9f5f-2f3f2aa28754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatingModelLSTMProcessor:\n",
    "    def __init__(self, overall_df, dates):\n",
    "        self.overall_df = overall_df\n",
    "        self.overall_df_value_col = \"value\"\n",
    "        self.dates = dates\n",
    "        self.dfs = []\n",
    "        \n",
    "        self.nfs = []\n",
    "        \n",
    "        self.forecasts = []\n",
    "        self.plotting_df = pd.DataFrame()\n",
    "        \n",
    "        self.maes = []\n",
    "        self.mses = []\n",
    "        self.mapes = []\n",
    "        self.nmses = []\n",
    "        \n",
    "        self.metrics_df = pd.DataFrame(columns = [\"Reference Date\", \"MAE\", \"MSE\", \"MAPE\", \"NMSE\"])\n",
    "        self.display_df = pd.DataFrame(columns = [\"Reference Date\", \"Target End Date\", \"Quantile\", \"Prediction\"])\n",
    "    \n",
    "    def create_training_dfs(self, value_col):\n",
    "        self.overall_df_value_col = value_col\n",
    "        for date in self.dates:\n",
    "            df = self.overall_df.loc[:date]\n",
    "            df['ds'] = df.index\n",
    "            df[\"unique_id\"] = \"series_1\"\n",
    "            df = df.rename(columns = {value_col: \"y\"})\n",
    "            self.dfs.append(df)\n",
    "    \n",
    "    def create_models(self, h, freq, model_names, level = []):\n",
    "        if not self.nfs:\n",
    "            for i in range(len(self.dfs)):\n",
    "                if not level:\n",
    "                    nf = NeuralForecast(models = [AutoLSTM(h = h, backend = \"optuna\")], freq = freq)\n",
    "                    nf.fit(df = self.dfs[i])\n",
    "                else:\n",
    "                    nf = NeuralForecast(models = [AutoLSTM(h = h, backend = \"optuna\", loss = MQLoss(level = level))], freq = freq)\n",
    "                    nf.fit(df = self.dfs[i])\n",
    "                \n",
    "                self.nfs.append(nf)\n",
    "                nf.save(path=f'AutoLSTM/updating_models/{model_names[i]}/')\n",
    "        \n",
    "        for i in range(len(self.dfs)):\n",
    "            y_hat = self.nfs[i].predict(df = self.dfs[i])\n",
    "            y_hat.set_index(\"ds\", inplace = True)\n",
    "            y_hat.drop(columns = \"unique_id\", inplace = True)\n",
    "            self.forecasts.append(y_hat)\n",
    "\n",
    "    def load_models(self, paths):\n",
    "        for i in range(len(paths)):\n",
    "            nf = NeuralForecast.load(path = paths[i])\n",
    "            self.nfs.append(nf)\n",
    "    \n",
    "        \n",
    "    def generate_color_map(self, columns, cmap_name = \"viridis\"):\n",
    "        intervals = set()\n",
    "        for col in columns:\n",
    "            if 'median' in col:\n",
    "                continue\n",
    "            parts = col.split('-')\n",
    "            number = parts[-1]\n",
    "            intervals.add(number)\n",
    "        \n",
    "        intervals = sorted(intervals, key=int)\n",
    "        cmap = plt.cm.get_cmap(cmap_name)\n",
    "        \n",
    "        n = len(intervals)\n",
    "        if n > 0:\n",
    "            half = np.linspace(0.2, 0.45, n // 2, endpoint=True)[::-1]  # lower intervals\n",
    "            upper = np.linspace(0.55, 0.8, n - n // 2, endpoint=True)  # higher intervals\n",
    "            sample_points = np.concatenate([half, upper])\n",
    "        else:\n",
    "            sample_points = np.array([])  # just median\n",
    "        \n",
    "        median_value = np.median(sample_points)\n",
    "        \n",
    "        color_mapping = {}\n",
    "        color_mapping['median'] = mcolors.to_hex(cmap(median_value))  # center of the colormap\n",
    "        for interval, point in zip(intervals, sample_points):\n",
    "            color_mapping[interval] = mcolors.to_hex(cmap(point))\n",
    "    \n",
    "        return color_mapping\n",
    "    \n",
    "    def create_graph(self):\n",
    "        \n",
    "        #Create color map for various confidence bands, only if levels are present\n",
    "        if len(self.forecasts[0].columns) != 1:\n",
    "            self.color_mapping = self.generate_color_map(columns = self.forecasts[0].columns)\n",
    "                \n",
    "        \n",
    "        for i in range(len(self.forecasts)):\n",
    "            #Plot the overall Real Data\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(x = self.overall_df.index, y = self.overall_df[self.overall_df_value_col], mode = \"lines\", name = \"Real Data\"))\n",
    "\n",
    "            \n",
    "            for col in self.forecasts[i].columns:\n",
    "                #Plot his first\n",
    "                if \"hi\" in col:\n",
    "                    number = col[-2:]\n",
    "                    fig.add_trace(go.Scatter(x = self.forecasts[i].index, y = self.forecasts[i][col], mode = \"lines\", name = col, \n",
    "                                             line = dict(color = self.color_mapping[number])))\n",
    "            \n",
    "            for col in self.forecasts[i].columns:\n",
    "                #Lows will go to corresponding his\n",
    "                if \"lo\" in col:\n",
    "                    number = col[-2:]\n",
    "                    fig.add_trace(go.Scatter(x = self.forecasts[i].index, y = self.forecasts[i][col], mode = \"lines\", name = col, \n",
    "                                             fill = \"tonexty\", fillcolor = self.color_mapping[number], line = dict(color = self.color_mapping[number])))\n",
    "            \n",
    "            for col in self.forecasts[i].columns:\n",
    "                #Median gets plotted last\n",
    "                if \"median\" in col:\n",
    "                    fig.add_trace(go.Scatter(x = self.forecasts[i].index, y = self.forecasts[i][col], mode = \"lines\", name = col, \n",
    "                                             line = dict(color = self.color_mapping[\"median\"])))\n",
    "            \n",
    "            #Case for if confidence interval not present\n",
    "            for col in self.forecasts[i].columns:\n",
    "                if col == \"AutoLSTM\":\n",
    "                    fig.add_trace(go.Scatter(x = self.forecasts[i].index, y = self.forecasts[i][\"AutoLSTM\"], mode = \"lines\", name = \"AutoLSTM\"))\n",
    "            \n",
    "            \n",
    "            fig.update_layout(title = f\"Updating Parameter LSTM Predictions, {self.dates[i]}\", xaxis_title = \"Date\", yaxis_title = \"Count\", hovermode = \"x\")\n",
    "            fig.show()\n",
    "        \n",
    "        \n",
    "    def calculate_metrics(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            mae = mean_absolute_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            mse = mean_squared_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            mape = mean_absolute_percentage_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i].iloc[:, 0])\n",
    "            nmse = mse/np.var(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index])\n",
    "            \n",
    "            self.maes.append(mae)\n",
    "            self.mses.append(mse)\n",
    "            self.mapes.append(mape)\n",
    "            self.nmses.append(nmse)\n",
    "    \n",
    "    def display_maes(self):\n",
    "        for i in range(len(self.maes)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Absolute Error for {english_date} model: {self.maes[i]}\")\n",
    "        \n",
    "    def display_mses(self):\n",
    "        for i in range(len(self.mses)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Squared Error for {english_date} model: {self.mses[i]}\")\n",
    "    \n",
    "    def display_mapes(self):\n",
    "        for i in range(len(self.mapes)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Absolute Percentage Error for {english_date} model: {self.mapes[i]}\")\n",
    "    \n",
    "    def display_nmses(self):\n",
    "        for i in range(len(self.nmses)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Normalized Mean Square Error for {english_date} model: {self.nmses[i]}\")\n",
    "        \n",
    "    def create_metrics_df(self):\n",
    "        for i in range(len(self.dates)):\n",
    "            self.metrics_df.loc[len(self.metrics_df)] = [self.dates[i], self.maes[i], self.mses[i], self.mapes[i], self.nmses[i]]\n",
    "    \n",
    "    def create_display_df(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            for index, row in self.forecasts[i].iterrows():\n",
    "                reference_date = self.dates[i]\n",
    "                target_end_date = index\n",
    "                \n",
    "                for col in self.forecasts[i].columns:\n",
    "                    value = self.forecasts[i].loc[target_end_date, col]\n",
    "                    if \"lo\" in col:\n",
    "                        number = int (col[-2:])\n",
    "                        alpha = 1 - (number / 100)\n",
    "                        quantile = alpha / 2\n",
    "                        self.display_df.loc[len(self.display_df)] = [reference_date, target_end_date, quantile, value]\n",
    "\n",
    "                    if col == \"AutoLSTM\" or \"median\" in col:\n",
    "                        quantile = 0.5\n",
    "                        self.display_df.loc[len(self.display_df)] = [reference_date, target_end_date, quantile, value]\n",
    "\n",
    "                    elif \"hi\" in col:\n",
    "                        number = int (col[-2:])\n",
    "                        alpha = 1 - (number / 100)\n",
    "                        quantile = 1 - (alpha / 2)\n",
    "                        self.display_df.loc[len(self.display_df)] = [reference_date, target_end_date, quantile, value]\n",
    "                \n",
    "        self.display_df.sort_values(by = [\"Reference Date\", \"Target End Date\", \"Quantile\"], inplace = True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af61d5-cbaa-45f8-b355-bb5a3f0cc971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor = UpdatingModelLSTMProcessor(overall_df = updated_df, dates = [\"2024-10-05\", \"2024-10-19\", \"2024-11-02\", \"2024-11-16\", \"2024-12-07\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4ee1f-d04d-40de-b6d0-e52c1d2d642c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_training_dfs(value_col = \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a053f-13c5-46d3-b499-3e398fea01cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_models(h = 4, freq = \"W-SAT\", model_names = [\"test_1\", \"test_2\", \"test_3\", \"test_4\", \"test_5\"], level = [80, 95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2cb6c5-7d55-499e-b952-b6f9af9b3fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.forecasts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380a8ef-a9ad-4ce8-ae3c-2834ad2249b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebc6fa-22d5-4765-bedb-888011c666e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.calculate_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c75be2-2ee0-45e1-9f99-6051a4cafbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a635971-ac5e-41f3-9440-1feef96d8c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_display_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9ec98-eb85-43ac-baf6-1dd2ccf6475e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a389e-b541-4bcc-a4d6-22de1c51ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_metrics_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de3515-7210-4ec8-93c0-a76d5fa2e2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbfb0c-03a3-4254-850f-ab345b0911e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f478cf62-0be3-4140-8c59-332c1e5fd037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68ba68-0540-46f1-a6d7-f50ed1993a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UProcessor2 = UpdatingModelLSTMProcessor(overall_df = updated_df, dates = [\"2024-10-05\", \"2024-10-19\", \"2024-11-02\", \"2024-11-16\", \"2024-12-07\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e7077-f408-44d6-a127-485a4cc65d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UProcessor2.create_training_dfs(value_col=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb7122-5f7b-41f2-a471-23af887351c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_paths = [\"AutoLSTM/updating_models/test_1/\", \"AutoLSTM/updating_models/test_2/\", \"AutoLSTM/updating_models/test_3/\",\n",
    "              \"AutoLSTM/updating_models/test_4/\", \"AutoLSTM/updating_models/test_5/\"]\n",
    "UProcessor2.load_models(paths = model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648b87f-c067-46be-8adb-da7104e3d9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UProcessor2.create_models(h = 4, freq = \"W-SAT\", model_names = [\"test_1\", \"test_2\", \"test_3\", \"test_4\", \"test_5\"], level = [80, 95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62e0c5-8a77-4d0b-8247-73d6ca50c1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UProcessor2.create_display_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21b143-d628-468c-80b7-657368d25114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UProcessor2.display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f16fb4-430b-476e-b47c-151625ba46a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016a8c8-1b20-4351-aef3-0395debd7e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
