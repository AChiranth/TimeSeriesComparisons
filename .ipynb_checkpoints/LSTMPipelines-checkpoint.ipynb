{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac7fdec-a1bd-4e31-9f74-6feacf65a01f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.25.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cufflinks as cf\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "cf.go_offline()\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from neuralforecast.auto import AutoLSTM\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models import LSTM\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b97f1e94-49de-4759-9b92-ec4b2aae1983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neuralforecast.losses.pytorch import MQLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7639236-2ea4-4865-ab18-50a25f21bfef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mAutoLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalid_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msearch_alg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_variant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasicVariantGenerator\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7fc9132ba850\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrefit_with_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ray'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Class for Automatic Hyperparameter Optimization, it builds on top of `ray` to\n",
       "give access to a wide variety of hyperparameter optimization tools ranging\n",
       "from classic grid search, to Bayesian optimization and HyperBand algorithm.\n",
       "\n",
       "The validation loss to be optimized is defined by the `config['loss']` dictionary\n",
       "value, the config also contains the rest of the hyperparameter search space.\n",
       "\n",
       "It is important to note that the success of this hyperparameter optimization\n",
       "heavily relies on a strong correlation between the validation and test periods.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "cls_model : PyTorch/PyTorchLightning model\n",
       "    See `neuralforecast.models` [collection here](https://nixtla.github.io/neuralforecast/models.html).\n",
       "h : int\n",
       "    Forecast horizon\n",
       "loss : PyTorch module\n",
       "    Instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).\n",
       "valid_loss : PyTorch module\n",
       "    Instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).\n",
       "config : dict or callable\n",
       "    Dictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n",
       "search_alg : ray.tune.search variant or optuna.sampler\n",
       "    For ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.html\n",
       "    For optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n",
       "num_samples : int\n",
       "    Number of hyperparameter optimization steps/samples.\n",
       "cpus : int (default=os.cpu_count())\n",
       "    Number of cpus to use during optimization. Only used with ray tune.\n",
       "gpus : int (default=torch.cuda.device_count())\n",
       "    Number of gpus to use during optimization, default all available. Only used with ray tune.\n",
       "refit_with_val : bool\n",
       "    Refit of best model should preserve val_size.\n",
       "verbose : bool\n",
       "    Track progress.\n",
       "alias : str, optional (default=None)\n",
       "    Custom name of the model.\n",
       "backend : str (default='ray')\n",
       "    Backend to use for searching the hyperparameter space, can be either 'ray' or 'optuna'.\n",
       "callbacks : list of callable, optional (default=None)\n",
       "    List of functions to call during the optimization process.\n",
       "    ray reference: https://docs.ray.io/en/latest/tune/tutorials/tune-metrics.html\n",
       "    optuna reference: https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/007_optuna_callback.html\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.11/site-packages/neuralforecast/auto.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AutoLSTM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5218041-870a-476d-a48a-424b1bcaf871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FixedModelLSTMProcessor:\n",
    "    def __init__(self, overall_df, dates):\n",
    "        self.overall_df = overall_df\n",
    "        self.overall_df_value_col = \"value\"\n",
    "        self.dates = dates\n",
    "        self.dfs = []\n",
    "        self.forecasts = []\n",
    "        self.plotting_df = pd.DataFrame()\n",
    "        \n",
    "        self.maes = []\n",
    "        self.mses = []\n",
    "        self.mapes = []\n",
    "        self.nmses = []\n",
    "        \n",
    "        self.metrics_df = pd.DataFrame(columns = [\"Reference Date\", \"MAE\", \"MSE\", \"MAPE\", \"NMSE\"])\n",
    "        self.display_df = pd.DataFrame(columns = [\"Reference Date\", \"Target End Date\", \"Prediction\"])\n",
    "    \n",
    "    def create_training_dfs(self, value_col):\n",
    "        self.overall_df_value_col = value_col\n",
    "        for date in self.dates:\n",
    "            df = self.overall_df.loc[:date]\n",
    "            df['ds'] = df.index\n",
    "            df[\"unique_id\"] = \"series_1\"\n",
    "            df = df.rename(columns = {value_col: \"y\"})\n",
    "            self.dfs.append(df)\n",
    "        \n",
    "    \n",
    "    def create_fixed_model(self, h, model_name, level = []):\n",
    "        #Creating AutoLSTM model and predicting with hyperparameter tuning by optuna backend. This is based upon the first training dataframe\n",
    "        initial_dataset, *_ = TimeSeriesDataset.from_df(self.dfs[0])\n",
    "        if not level:\n",
    "            LSTMmodel = AutoLSTM(h = h, backend = \"optuna\")\n",
    "            LSTMmodel.fit(dataset = initial_dataset)\n",
    "        else:\n",
    "            LSTMmodel = AutoLSTM(h = h, backend = \"optuna\", loss = MQLoss(level = level))\n",
    "            LSTMmodel.fit(dataset = initial_dataset)\n",
    "        \n",
    "        for i in range(len(self.dfs)):\n",
    "            dataset, *_ = TimeSeriesDataset.from_df(self.dfs[i])\n",
    "            y_hat = LSTMmodel.predict(dataset = dataset)\n",
    "            start_date = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            horizon_dates = [start_date + timedelta(weeks=j) for j in range(1, h+1)]\n",
    "            \n",
    "            \n",
    "            y_hat = np.array(y_hat)\n",
    "            if y_hat.ndim == 1:\n",
    "                y_hat = y_hat.reshape(-1, 1)\n",
    "\n",
    "            if levels:\n",
    "                column_names = [\"LSTM-Median\", f\"LSTM-lo-{levels[-1]}\", f\"LSTM-lo-{levels[0]}\", f\"LSTM-hi-{levels[0]}\", f\"LSTM-hi-{levels[-1]}\"]\n",
    "            else:\n",
    "                column_names = [\"LSTM-Median\"]\n",
    "            fc = pd.DataFrame(y_hat, index=pd.to_datetime(horizon_dates), columns=column_names)\n",
    "\n",
    "            self.forecasts.append(fc)\n",
    "        \n",
    "        LSTMmodel.save(path=f'./AutoLSTM/fixed_models/{model_name}/')\n",
    "    \n",
    "    def create_graph(self):\n",
    "        self.plotting_df.index = self.overall_df.index\n",
    "        self.plotting_df[\"Real Data\"] = self.overall_df[self.overall_df_value_col]\n",
    "        \n",
    "        for i in range(len(self.forecasts)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            \n",
    "            self.plotting_df[f\"{english_date} Model\"] = self.forecasts[i][\"LSTM-Median\"]\n",
    "        \n",
    "        self.plotting_df.iplot(xTitle = \"Date\", yTitle = \"Count\", title = \"Fixed Parameter LSTM Predictions\")\n",
    "    \n",
    "    def calculate_metrics(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            mae = mean_absolute_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i][0])\n",
    "            mse = mean_squared_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i][0])\n",
    "            mape = mean_absolute_percentage_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i][0])\n",
    "            nmse = mse/np.var(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index])\n",
    "            \n",
    "            self.maes.append(mae)\n",
    "            self.mses.append(mse)\n",
    "            self.mapes.append(mape)\n",
    "            self.nmses.append(nmse)\n",
    "    \n",
    "    def display_maes(self):\n",
    "        for i in range(len(self.maes)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Absolute Error for {english_date} model: {self.maes[i]}\")\n",
    "        \n",
    "    def display_mses(self):\n",
    "        for i in range(len(self.mses)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Squared Error for {english_date} model: {self.mses[i]}\")\n",
    "    \n",
    "    def display_mapes(self):\n",
    "        for i in range(len(self.mapes)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Absolute Percentage Error for {english_date} model: {self.mapes[i]}\")\n",
    "    \n",
    "    def display_nmses(self):\n",
    "        for i in range(len(self.nmses)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Normalized Mean Square Error for {english_date} model: {self.nmses[i]}\")\n",
    "    \n",
    "    def create_metrics_df(self):\n",
    "        for i in range(len(self.dates)):\n",
    "            self.metrics_df.loc[len(self.metrics_df)] = [self.dates[i], self.maes[i], self.mses[i], self.mapes[i], self.nmses[i]]\n",
    "        \n",
    "            \n",
    "    def create_display_df(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            for index, row in self.forecasts[i].iterrows():\n",
    "                reference_date = self.dates[i]\n",
    "                target_end_date = index\n",
    "                value = row[0]\n",
    "                self.display_df.loc[len(self.display_df)] = [reference_date, target_end_date, value]\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25af5694-c6c4-4a04-9c64-4e4590e0681f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_df = pd.read_csv(\"https://raw.githubusercontent.com/cdcepi/FluSight-forecast-hub/refs/heads/main/target-data/target-hospital-admissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c72ba56f-2195-457c-a505-1cdb8a1b99f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_df = updated_df[updated_df[\"location_name\"] == \"US\"]\n",
    "updated_df = updated_df[[\"date\", \"value\"]]\n",
    "updated_df[\"date\"] = pd.to_datetime(updated_df[\"date\"])\n",
    "updated_df.set_index(\"date\", inplace = True)\n",
    "updated_df.sort_values(by = \"date\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7c1aab4-a5b1-4276-8b0d-bddfb2e31399",
   "metadata": {},
   "outputs": [],
   "source": [
    "Processor = FixedModelLSTMProcessor(overall_df = updated_df, dates = [\"2024-10-05\", \"2024-10-19\", \"2024-11-02\", \"2024-11-16\", \"2024-12-07\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b7451-690c-4124-94cf-8f8323531aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bddc3d7-658b-49e9-885a-e15a02977b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_training_dfs(value_col = \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aeb46fa9-763b-44ac-a535-c98b7ebc5535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-01 17:08:41,900] A new study created in memory with name: no-name-d9d426ef-68fb-4ae1-bec5-48e3c745500c\n",
      "/home/hmf6av/.local/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py:291: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "[rank: 0] Seed set to 7\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MQLoss        | 5      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 1.1 M  | train\n",
      "4 | context_adapter | Linear        | 60.2 K | train\n",
      "5 | mlp_decoder     | MLP           | 7.2 K  | train\n",
      "----------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "5         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.614     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f437c596c3443c78b1baa9a55f362e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n",
      "[I 2025-04-01 17:08:47,548] Trial 0 finished with value: 18.08902359008789 and parameters: {'encoder_hidden_size': 300, 'encoder_n_layers': 2, 'context_size': 50, 'decoder_hidden_size': 128, 'learning_rate': 0.004265052633803513, 'max_steps': 500, 'batch_size': 16, 'random_seed': 7, 'input_size': 64, 'inference_input_size': -4}. Best is trial 0 with value: 18.08902359008789.\n",
      "/home/hmf6av/.local/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py:291: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "[rank: 0] Seed set to 2\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MQLoss        | 5      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 10.6 K | train\n",
      "4 | context_adapter | Linear        | 1.0 K  | train\n",
      "5 | mlp_decoder     | MLP           | 5.6 K  | train\n",
      "----------------------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "5         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8e499fd00b4f7ba780f75473741f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n",
      "[I 2025-04-01 17:08:51,309] Trial 1 finished with value: 161.60263061523438 and parameters: {'encoder_hidden_size': 50, 'encoder_n_layers': 1, 'context_size': 5, 'decoder_hidden_size': 512, 'learning_rate': 0.0006381139628800947, 'max_steps': 500, 'batch_size': 16, 'random_seed': 2, 'input_size': 256, 'inference_input_size': -4}. Best is trial 0 with value: 18.08902359008789.\n",
      "/home/hmf6av/.local/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py:291: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "[rank: 0] Seed set to 7\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MQLoss        | 5      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 122 K  | train\n",
      "4 | context_adapter | Linear        | 2.0 K  | train\n",
      "5 | mlp_decoder     | MLP           | 2.8 K  | train\n",
      "----------------------------------------------------------\n",
      "126 K     Trainable params\n",
      "5         Non-trainable params\n",
      "126 K     Total params\n",
      "0.507     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f694e7de454f939f3bb75d97f54358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n",
      "[I 2025-04-01 17:08:55,235] Trial 2 finished with value: 30.240930557250977 and parameters: {'encoder_hidden_size': 100, 'encoder_n_layers': 2, 'context_size': 5, 'decoder_hidden_size': 256, 'learning_rate': 0.005179068659529202, 'max_steps': 500, 'batch_size': 16, 'random_seed': 7, 'input_size': 16, 'inference_input_size': -4}. Best is trial 0 with value: 18.08902359008789.\n",
      "/home/hmf6av/.local/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py:291: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "[rank: 0] Seed set to 11\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MQLoss        | 5      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 805 K  | train\n",
      "4 | context_adapter | Linear        | 40.2 K | train\n",
      "5 | mlp_decoder     | MLP           | 14.3 K | train\n",
      "----------------------------------------------------------\n",
      "860 K     Trainable params\n",
      "5         Non-trainable params\n",
      "860 K     Total params\n",
      "3.441     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5524a3e139764cfeb021efa71dd096ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "[I 2025-04-01 17:09:13,962] Trial 3 finished with value: 15.937479019165039 and parameters: {'encoder_hidden_size': 200, 'encoder_n_layers': 3, 'context_size': 50, 'decoder_hidden_size': 256, 'learning_rate': 0.0020157888938181134, 'max_steps': 1000, 'batch_size': 32, 'random_seed': 11, 'input_size': 256, 'inference_input_size': -4}. Best is trial 3 with value: 15.937479019165039.\n",
      "/home/hmf6av/.local/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py:291: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "[rank: 0] Seed set to 4\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MQLoss        | 5      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 1.1 M  | train\n",
      "4 | context_adapter | Linear        | 60.2 K | train\n",
      "5 | mlp_decoder     | MLP           | 3.6 K  | train\n",
      "----------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "5         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.599     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b06b0980bb540768ed84fc4cf487a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n",
      "[I 2025-04-01 17:09:18,372] Trial 4 finished with value: 169.658935546875 and parameters: {'encoder_hidden_size': 300, 'encoder_n_layers': 2, 'context_size': 50, 'decoder_hidden_size': 64, 'learning_rate': 0.023263979284516678, 'max_steps': 500, 'batch_size': 16, 'random_seed': 4, 'input_size': 16, 'inference_input_size': -4}. Best is trial 3 with value: 15.937479019165039.\n",
      "/home/hmf6av/.local/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py:291: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "[rank: 0] Seed set to 13\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MQLoss        | 5      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 162 K  | train\n",
      "4 | context_adapter | Linear        | 40.2 K | train\n",
      "5 | mlp_decoder     | MLP           | 14.3 K | train\n",
      "----------------------------------------------------------\n",
      "216 K     Trainable params\n",
      "5         Non-trainable params\n",
      "216 K     Total params\n",
      "0.868     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67eafd35e6bf4fc3b04ae2f4e1a7539b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "[I 2025-04-01 17:09:35,338] Trial 6 finished with value: 22.53645896911621 and parameters: {'encoder_hidden_size': 50, 'encoder_n_layers': 2, 'context_size': 50, 'decoder_hidden_size': 256, 'learning_rate': 0.0020049435389831267, 'max_steps': 1000, 'batch_size': 16, 'random_seed': 6, 'input_size': 16, 'inference_input_size': -4}. Best is trial 3 with value: 15.937479019165039.\n",
      "/home/hmf6av/.local/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py:291: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "[rank: 0] Seed set to 12\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MQLoss        | 5      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 283 K  | train\n",
      "4 | context_adapter | Linear        | 2.0 K  | train\n",
      "5 | mlp_decoder     | MLP           | 709    | train\n",
      "----------------------------------------------------------\n",
      "286 K     Trainable params\n",
      "5         Non-trainable params\n",
      "286 K     Total params\n",
      "1.145     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d411633e0e434d0489bd9661c345a60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n",
      "[I 2025-04-01 17:09:40,084] Trial 7 finished with value: 552.7879028320312 and parameters: {'encoder_hidden_size': 100, 'encoder_n_layers': 4, 'context_size': 5, 'decoder_hidden_size': 64, 'learning_rate': 0.007739388661148046, 'max_steps': 500, 'batch_size': 16, 'random_seed': 12, 'input_size': 256, 'inference_input_size': -4}. Best is trial 3 with value: 15.937479019165039.\n",
      "/home/hmf6av/.local/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py:291: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "[rank: 0] Seed set to 16\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MQLoss        | 5      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 1.1 M  | train\n",
      "4 | context_adapter | Linear        | 40.2 K | train\n",
      "5 | mlp_decoder     | MLP           | 28.7 K | train\n",
      "----------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "5         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.784     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3faca0d46654503affa8090c1633105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "[I 2025-04-01 17:10:02,564] Trial 8 finished with value: 419.05206298828125 and parameters: {'encoder_hidden_size': 200, 'encoder_n_layers': 4, 'context_size': 50, 'decoder_hidden_size': 512, 'learning_rate': 0.02452793198786571, 'max_steps': 1000, 'batch_size': 32, 'random_seed': 16, 'input_size': -4, 'inference_input_size': -4}. Best is trial 3 with value: 15.937479019165039.\n",
      "/home/hmf6av/.local/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py:291: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "[rank: 0] Seed set to 13\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MQLoss        | 5      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "4 | context_adapter | Linear        | 8.0 K  | train\n",
      "5 | mlp_decoder     | MLP           | 1.0 K  | train\n",
      "----------------------------------------------------------\n",
      "493 K     Trainable params\n",
      "5         Non-trainable params\n",
      "493 K     Total params\n",
      "1.972     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9928a8bbc5904c1594706a740c07fd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n",
      "[I 2025-04-01 17:10:10,062] Trial 9 finished with value: 84.0155029296875 and parameters: {'encoder_hidden_size': 200, 'encoder_n_layers': 2, 'context_size': 10, 'decoder_hidden_size': 64, 'learning_rate': 0.014254060029369362, 'max_steps': 500, 'batch_size': 32, 'random_seed': 13, 'input_size': 256, 'inference_input_size': -4}. Best is trial 3 with value: 15.937479019165039.\n",
      "[rank: 0] Seed set to 11\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MQLoss        | 5      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 805 K  | train\n",
      "4 | context_adapter | Linear        | 40.2 K | train\n",
      "5 | mlp_decoder     | MLP           | 14.3 K | train\n",
      "----------------------------------------------------------\n",
      "860 K     Trainable params\n",
      "5         Non-trainable params\n",
      "860 K     Total params\n",
      "3.441     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756b53f70a064d759f574bb733c1f999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1a60d8d6704eabbc8d451a010779c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691f92073be6428b9fdcaa858b658b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a4342c87294d8eab7ebdc1e21485bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a5afb2a3404e569950236faed52888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af73f2287914059b535133b59873074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Processor.create_fixed_model(h = 4, model_name = \"test_model\", levels = [80, 95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e846a64c-4fcf-4473-a2aa-9bae7a224652",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM-Median</th>\n",
       "      <th>LSTM-lo-95</th>\n",
       "      <th>LSTM-lo-80</th>\n",
       "      <th>LSTM-hi-80</th>\n",
       "      <th>LSTM-hi-95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-09</th>\n",
       "      <td>565.854248</td>\n",
       "      <td>376.104614</td>\n",
       "      <td>488.344299</td>\n",
       "      <td>684.059326</td>\n",
       "      <td>738.332581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-16</th>\n",
       "      <td>524.021484</td>\n",
       "      <td>420.966553</td>\n",
       "      <td>443.558777</td>\n",
       "      <td>660.987000</td>\n",
       "      <td>720.904724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-23</th>\n",
       "      <td>529.932190</td>\n",
       "      <td>409.866760</td>\n",
       "      <td>448.480347</td>\n",
       "      <td>634.575745</td>\n",
       "      <td>725.592896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-30</th>\n",
       "      <td>495.173828</td>\n",
       "      <td>430.132263</td>\n",
       "      <td>411.099365</td>\n",
       "      <td>601.863647</td>\n",
       "      <td>655.011841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LSTM-Median  LSTM-lo-95  LSTM-lo-80  LSTM-hi-80  LSTM-hi-95\n",
       "2024-11-09   565.854248  376.104614  488.344299  684.059326  738.332581\n",
       "2024-11-16   524.021484  420.966553  443.558777  660.987000  720.904724\n",
       "2024-11-23   529.932190  409.866760  448.480347  634.575745  725.592896\n",
       "2024-11-30   495.173828  430.132263  411.099365  601.863647  655.011841"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Processor.forecasts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa42b8-67e0-4800-9e36-fe5c37484705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600ccd3-0aec-4907-a43c-f7e663898941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.plotting_df.iloc[-16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770589c4-ba33-44fc-92b3-1fd18b6ed5e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.forecasts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57296ec2-66d4-4f08-a254-e4c3da164688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c00a3-28e6-4f35-98fb-4d988b65a22d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.overall_df[\"value\"].loc[Processor.forecasts[1].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6257d1e-4ecd-4600-9d26-2c5c265e8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "Processor.calculate_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd11a4-68cd-42f5-a817-85182eca7b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f83c6f-7c92-4e47-8695-83f3a9804cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2bfed-182e-4e27-91e9-4d6a8b4f8226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.mapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c64886-a4b5-4bbe-80fe-60ba5f79caa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_display_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680da260-4656-47e6-b153-bd335be097ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa4533-8feb-4065-84d1-84abebc9ae93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.create_metrics_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bdb5ad-2bf1-4c53-b9ab-687d506e95f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa836c-4f69-4929-b34d-ed24b4087651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0803a22-783e-4bde-9f5f-2f3f2aa28754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatingModelLSTMProcessor:\n",
    "    def __init__(self, overall_df, dates):\n",
    "        self.overall_df = overall_df\n",
    "        self.overall_df_value_col = \"value\"\n",
    "        self.dates = dates\n",
    "        self.dfs = []\n",
    "        self.forecasts = []\n",
    "        self.plotting_df = pd.DataFrame()\n",
    "        \n",
    "        self.maes = []\n",
    "        self.mses = []\n",
    "        self.mapes = []\n",
    "        self.nmses = []\n",
    "        \n",
    "        self.metrics_df = pd.DataFrame(columns = [\"Reference Date\", \"MAE\", \"MSE\", \"MAPE\", \"NMSE\"])\n",
    "        self.display_df = pd.DataFrame(columns = [\"Reference Date\", \"Target End Date\", \"Prediction\"])\n",
    "    \n",
    "    def create_training_dfs(self, value_col):\n",
    "        self.overall_df_value_col = value_col\n",
    "        for date in self.dates:\n",
    "            df = self.overall_df.loc[:date]\n",
    "            df['ds'] = df.index\n",
    "            df[\"unique_id\"] = \"series_1\"\n",
    "            df = df.rename(columns = {value_col: \"y\"})\n",
    "            self.dfs.append(df)\n",
    "    \n",
    "    def create_models(self, h, model_names, levels = []):\n",
    "        for i in range(len(self.dfs)):\n",
    "            dataset, *_ = TimeSeriesDataset.from_df(self.dfs[i])\n",
    "            if not levels:\n",
    "                LSTMmodel = AutoLSTM(h = h, backend = \"optuna\")\n",
    "                LSTMmodel.fit(dataset = dataset)\n",
    "            else:\n",
    "                LSTMmodel = AutoLSTM(h = h, backend = \"optuna\", loss = MQLoss(level = level))\n",
    "                LSTMmodel.fit(dataset = initial_dataset)\n",
    "            \n",
    "            y_hat = LSTMmodel.predict(dataset = dataset)\n",
    "            start_date = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            horizon_dates = [start_date + timedelta(weeks=j) for j in range(1, h+1)]\n",
    "            \n",
    "            y_hat = np.array(y_hat)\n",
    "            if y_hat.ndim == 1:\n",
    "                y_hat = y_hat.reshape(-1, 1)\n",
    "                \n",
    "                \n",
    "            if levels:\n",
    "                column_names = [\"LSTM-Median\", f\"LSTM-lo-{levels[-1]}\", f\"LSTM-lo-{levels[0]}\", f\"LSTM-hi-{levels[0]}\", f\"LSTM-hi-{levels[-1]}\"]\n",
    "            else:\n",
    "                column_names = [\"LSTM-Median\"]\n",
    "            fc = pd.DataFrame(y_hat, index=pd.to_datetime(horizon_dates), columns=column_names)\n",
    "\n",
    "            self.forecasts.append(fc)\n",
    "            LSTMmodel.save(path=f'./AutoLSTM/updating_models/{model_names[i]}.ckpt')\n",
    "    \n",
    "    def create_graph(self):\n",
    "        self.plotting_df.index = self.overall_df.index\n",
    "        self.plotting_df[\"Real Data\"] = self.overall_df[self.overall_df_value_col]\n",
    "        \n",
    "        for i in range(len(self.forecasts)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            \n",
    "            self.plotting_df[f\"{english_date} Model\"] = self.forecasts[i][\"LSTM-Median\"]\n",
    "        \n",
    "        self.plotting_df.iplot(xTitle = \"Date\", yTitle = \"Count\", title = \"Updating Parameter LSTM Predictions\")\n",
    "    \n",
    "    def calculate_metrics(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            mae = mean_absolute_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i][0])\n",
    "            mse = mean_squared_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i][0])\n",
    "            mape = mean_absolute_percentage_error(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index], self.forecasts[i][0])\n",
    "            nmse = mse/np.var(self.overall_df[self.overall_df_value_col].loc[self.forecasts[i].index])\n",
    "            \n",
    "            self.maes.append(mae)\n",
    "            self.mses.append(mse)\n",
    "            self.mapes.append(mape)\n",
    "            self.nmses.append(nmse)\n",
    "    \n",
    "    def display_maes(self):\n",
    "        for i in range(len(self.maes)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Absolute Error for {english_date} model: {self.maes[i]}\")\n",
    "        \n",
    "    def display_mses(self):\n",
    "        for i in range(len(self.mses)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Squared Error for {english_date} model: {self.mses[i]}\")\n",
    "    \n",
    "    def display_mapes(self):\n",
    "        for i in range(len(self.mapes)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Mean Absolute Percentage Error for {english_date} model: {self.mapes[i]}\")\n",
    "    \n",
    "    def display_nmses(self):\n",
    "        for i in range(len(self.nmses)):\n",
    "            date_obj = datetime.strptime(self.dates[i], \"%Y-%m-%d\")\n",
    "            english_date = date_obj.strftime(\"%B %d, %Y\")\n",
    "            print(f\"Normalized Mean Square Error for {english_date} model: {self.nmses[i]}\")\n",
    "        \n",
    "    def create_metrics_df(self):\n",
    "        for i in range(len(self.dates)):\n",
    "            self.metrics_df.loc[len(self.metrics_df)] = [self.dates[i], self.maes[i], self.mses[i], self.mapes[i], self.nmses[i]]\n",
    "    \n",
    "    def create_display_df(self):\n",
    "        for i in range(len(self.forecasts)):\n",
    "            for index, row in self.forecasts[i].iterrows():\n",
    "                reference_date = self.dates[i]\n",
    "                target_end_date = index\n",
    "                value = row[0]\n",
    "                self.display_df.loc[len(self.display_df)] = [reference_date, target_end_date, value]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af61d5-cbaa-45f8-b355-bb5a3f0cc971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor = UpdatingModelLSTMProcessor(overall_df = updated_df, dates = [\"2024-10-05\", \"2024-10-19\", \"2024-11-02\", \"2024-11-16\", \"2024-12-07\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c973a910-9431-4300-a528-c1d22b477b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4547824-a6bc-4ba5-8de1-54da4d7a7e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4ee1f-d04d-40de-b6d0-e52c1d2d642c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_training_dfs(value_col = \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f4a20-34c0-4fe6-ba4d-2d50c2e20b52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a053f-13c5-46d3-b499-3e398fea01cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_models(h = 4, model_names = [\"test_1\", \"test_2\", \"test_3\", \"test_4\", \"test_5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2cb6c5-7d55-499e-b952-b6f9af9b3fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.forecasts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380a8ef-a9ad-4ce8-ae3c-2834ad2249b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebc6fa-22d5-4765-bedb-888011c666e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.calculate_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c75be2-2ee0-45e1-9f99-6051a4cafbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a635971-ac5e-41f3-9440-1feef96d8c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_display_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9ec98-eb85-43ac-baf6-1dd2ccf6475e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a389e-b541-4bcc-a4d6-22de1c51ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UpdatingProcessor.create_metrics_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2c5c9-bc2f-4581-b6c7-223d310766b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UpdatingProcessor.metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e2ba3-151b-4699-aaf7-96b9a09110ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Processor.metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e12d200-1536-4e97-a78a-4b7936b735f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel = AutoLSTM(h = 4, backend = \"optuna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e233f0b-1bcd-456c-9458-829539c98066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoLSTM' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mLSTMmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./AutoLSTM/updating_models/test_model.ckpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1930\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AutoLSTM' object has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "LSTMmodel.load(path=f'./AutoLSTM/updating_models/test_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3da1c66f-e815-4cfa-9a3b-4225270b1717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "nf = NeuralForecast(models = [LSTM(h = 4)], freq = \"W-SAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79834e77-5644-44a3-8e9a-b79ec5784182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/sfs/gpfs/tardis/home/hmf6av/TimeSeriesComparisons/AutoLSTM/fixed_models/test_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./AutoLSTM/fixed_models/test_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/neuralforecast/core.py:1512\u001b[0m, in \u001b[0;36mNeuralForecast.load\u001b[0;34m(path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     path \u001b[38;5;241m=\u001b[39m path[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1511\u001b[0m fs, _, _ \u001b[38;5;241m=\u001b[39m fsspec\u001b[38;5;241m.\u001b[39mget_fs_token_paths(path)\n\u001b[0;32m-> 1512\u001b[0m files \u001b[38;5;241m=\u001b[39m [f\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m fs\u001b[38;5;241m.\u001b[39misfile(f)]\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# Load models\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m models_ckpt \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m/apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages/fsspec/implementations/local.py:66\u001b[0m, in \u001b[0;36mLocalFileSystem.ls\u001b[0;34m(self, path, detail, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m it]\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [posixpath\u001b[38;5;241m.\u001b[39mjoin(path, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m]\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/sfs/gpfs/tardis/home/hmf6av/TimeSeriesComparisons/AutoLSTM/fixed_models/test_model'"
     ]
    }
   ],
   "source": [
    "nf.load(path=f'./AutoLSTM/fixed_models/test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "781c9a16-67e2-41b2-b625-b191d06a8ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mAutoLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "BaseAuto.save\n",
       "\n",
       "Save the fitted model to disk.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`path`: str, path to save the model.<br>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AutoLSTM.save?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8314096d-383e-4403-b105-c9954f78c6b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/hmf6av/TimeSeriesComparisons\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78e97184-67bd-4471-a22e-15acefd73f92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMAPipelines.ipynb\t        lightning_logs\n",
      " AutoARIMA\t\t        LSTMHyperParameter.ipynb\n",
      " AutoLSTM\t\t        LSTMPipelines.ipynb\n",
      " AutoLSTM.ipynb\t\t        TimeGPT-ARIMA-LSTM-TFT.ipynb\n",
      " CESPipelines.ipynb\t       'TimeGPT Notebook.ipynb'\n",
      " checkpoints\t\t        Untitled.ipynb\n",
      " ETSPipelines.ipynb\t       'Updated Window Experiments.ipynb'\n",
      " HyperParamOptimization.ipynb   WindowExperiments.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3599d0-599c-4d19-aa31-caeb0e3cebb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
