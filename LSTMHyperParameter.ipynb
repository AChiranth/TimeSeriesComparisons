{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6abbccdb-ee00-4e21-99bf-64ceb3fa9376",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.25.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cufflinks as cf\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "cf.go_offline()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from neuralforecast.auto import AutoLSTM\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3f8a4cc-82a7-4373-97b4-8c9f9527a7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe9617e-6000-40a3-b3a8-3c455fe280fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_df = pd.read_csv(\"https://raw.githubusercontent.com/cdcepi/FluSight-forecast-hub/refs/heads/main/target-data/target-hospital-admissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abd97cc-7f42-49ae-931d-18f6b9532ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-05</th>\n",
       "      <td>1092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-12</th>\n",
       "      <td>1164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-19</th>\n",
       "      <td>1493.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-26</th>\n",
       "      <td>1603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-05</th>\n",
       "      <td>1791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-18</th>\n",
       "      <td>32561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-25</th>\n",
       "      <td>39927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>50272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-08</th>\n",
       "      <td>52211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-15</th>\n",
       "      <td>41658.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              value\n",
       "date               \n",
       "2022-02-05   1092.0\n",
       "2022-02-12   1164.0\n",
       "2022-02-19   1493.0\n",
       "2022-02-26   1603.0\n",
       "2022-03-05   1791.0\n",
       "...             ...\n",
       "2025-01-18  32561.0\n",
       "2025-01-25  39927.0\n",
       "2025-02-01  50272.0\n",
       "2025-02-08  52211.0\n",
       "2025-02-15  41658.0\n",
       "\n",
       "[159 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df = updated_df[updated_df[\"location_name\"] == \"US\"]\n",
    "updated_df = updated_df[[\"date\", \"value\"]]\n",
    "updated_df[\"date\"] = pd.to_datetime(updated_df[\"date\"])\n",
    "updated_df.set_index(\"date\", inplace = True)\n",
    "updated_df.sort_values(by = \"date\", inplace = True)\n",
    "updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d54b22-a92d-4b2e-bc6f-fdc5c8e1fe5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-05</th>\n",
       "      <td>1092.0</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>series_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-12</th>\n",
       "      <td>1164.0</td>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>series_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-19</th>\n",
       "      <td>1493.0</td>\n",
       "      <td>2022-02-19</td>\n",
       "      <td>series_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-26</th>\n",
       "      <td>1603.0</td>\n",
       "      <td>2022-02-26</td>\n",
       "      <td>series_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-05</th>\n",
       "      <td>1791.0</td>\n",
       "      <td>2022-03-05</td>\n",
       "      <td>series_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-07</th>\n",
       "      <td>223.0</td>\n",
       "      <td>2024-09-07</td>\n",
       "      <td>series_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-14</th>\n",
       "      <td>319.0</td>\n",
       "      <td>2024-09-14</td>\n",
       "      <td>series_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-21</th>\n",
       "      <td>293.0</td>\n",
       "      <td>2024-09-21</td>\n",
       "      <td>series_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-28</th>\n",
       "      <td>223.0</td>\n",
       "      <td>2024-09-28</td>\n",
       "      <td>series_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-05</th>\n",
       "      <td>287.0</td>\n",
       "      <td>2024-10-05</td>\n",
       "      <td>series_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 y         ds unique_id\n",
       "date                                   \n",
       "2022-02-05  1092.0 2022-02-05  series_1\n",
       "2022-02-12  1164.0 2022-02-12  series_1\n",
       "2022-02-19  1493.0 2022-02-19  series_1\n",
       "2022-02-26  1603.0 2022-02-26  series_1\n",
       "2022-03-05  1791.0 2022-03-05  series_1\n",
       "...            ...        ...       ...\n",
       "2024-09-07   223.0 2024-09-07  series_1\n",
       "2024-09-14   319.0 2024-09-14  series_1\n",
       "2024-09-21   293.0 2024-09-21  series_1\n",
       "2024-09-28   223.0 2024-09-28  series_1\n",
       "2024-10-05   287.0 2024-10-05  series_1\n",
       "\n",
       "[140 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's create an AutoLSTM model that is trained up to October 5, fix these parameters and create expanding window models\n",
    "oct1stweekdf = updated_df.loc[:\"2024-10-05\"]\n",
    "oct1stweekdf['ds'] = oct1stweekdf.index\n",
    "oct1stweekdf[\"unique_id\"] = \"series_1\"\n",
    "oct1stweekdf = oct1stweekdf.rename(columns = {\"value\": \"y\"})\n",
    "oct1stweekdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7d5249-a3cc-4383-9249-8b9e962d3f63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset, *_ = TimeSeriesDataset.from_df(oct1stweekdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a738398-5d93-4563-9319-030466dcd145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=515532)\u001b[0m /home/hmf6av/.local/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m [rank: 0] Seed set to 1\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 0 | loss            | MAE           | 0      | train\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 4 | context_adapter | Linear        | 8.0 K  | train\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 494 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 494 K     Total params\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 1.978     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.500, train_loss_epoch=3.500]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.020, train_loss_epoch=3.020]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.150, train_loss_epoch=2.150]        \n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 73.99it/s, v_num=2587929, train_loss_step=2.050, train_loss_epoch=2.150]\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 72.14it/s, v_num=2587929, train_loss_step=2.050, train_loss_epoch=2.050]\n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.050, train_loss_epoch=2.050]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.480, train_loss_epoch=1.480]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.915, train_loss_epoch=0.915]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.801, train_loss_epoch=0.801]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.700, train_loss_epoch=0.700]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.653, train_loss_epoch=0.653]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.582, train_loss_epoch=0.582]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.529, train_loss_epoch=0.529]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.473, train_loss_epoch=0.473]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.454, train_loss_epoch=0.454]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 76.85it/s, v_num=2587929, train_loss_step=0.418, train_loss_epoch=0.450]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.06it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=677.0]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=677.0]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=677.0]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=677.0]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=677.0]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=677.0]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=677.0]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=677.0]        \n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 74.86it/s, v_num=2587929, train_loss_step=0.269, train_loss_epoch=0.241, valid_loss=677.0]\n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=677.0]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=677.0]        \n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 75.02it/s, v_num=2587929, train_loss_step=0.203, train_loss_epoch=0.234, valid_loss=677.0]\n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=677.0]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=677.0]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=677.0]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=677.0]        \n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 71.18it/s, v_num=2587929, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=677.0]\n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=677.0]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=677.0]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 75.07it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.174, valid_loss=677.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.02it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=159.0]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=159.0]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=159.0]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=159.0]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=159.0]        \n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 75.71it/s, v_num=2587929, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=159.0]\n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=159.0]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=159.0]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=159.0]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=159.0]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=159.0]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=159.0]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=159.0]        \n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 71.94it/s, v_num=2587929, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=159.0]\n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=159.0]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=159.0]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=159.0]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=159.0]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=159.0]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=159.0]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=159.0]        \n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 73.09it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=159.0]\n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=159.0]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 77.00it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.0989, valid_loss=159.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.68it/s]\u001b[A\n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=113.0]          \n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 76.11it/s, v_num=2587929, train_loss_step=0.103, train_loss_epoch=0.124, valid_loss=113.0]  \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=113.0]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=113.0]          \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]          \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0821, train_loss_epoch=0.0821, valid_loss=113.0]        \n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 74.07it/s, v_num=2587929, train_loss_step=0.084, train_loss_epoch=0.0821, valid_loss=113.0] \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.084, train_loss_epoch=0.084, valid_loss=113.0]         \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.096, train_loss_epoch=0.096, valid_loss=113.0]          \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=113.0]        \n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 75.42it/s, v_num=2587929, train_loss_step=0.0881, train_loss_epoch=0.0956, valid_loss=113.0]\n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0881, train_loss_epoch=0.0881, valid_loss=113.0]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0895, train_loss_epoch=0.0895, valid_loss=113.0]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=113.0]          \n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 73.02it/s, v_num=2587929, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=113.0]\n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=113.0]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=113.0]          \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]          \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0919, train_loss_epoch=0.0919, valid_loss=113.0]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=113.0]          \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 73.98it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.74it/s]\u001b[A\n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=112.0]          \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0937, train_loss_epoch=0.0937, valid_loss=112.0]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0934, train_loss_epoch=0.0934, valid_loss=112.0]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0935, train_loss_epoch=0.0935, valid_loss=112.0]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=112.0]          \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0922, train_loss_epoch=0.0922, valid_loss=112.0]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=112.0]          \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=112.0]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.084, train_loss_epoch=0.084, valid_loss=112.0]          \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=112.0]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=112.0]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=112.0]          \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0866, train_loss_epoch=0.0866, valid_loss=112.0]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=112.0]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0782, train_loss_epoch=0.0782, valid_loss=112.0]        \n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 73.13it/s, v_num=2587929, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=112.0]  \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=112.0]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0999, train_loss_epoch=0.0999, valid_loss=112.0]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 76.10it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.090, valid_loss=112.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.69it/s]\u001b[A\n",
      "                                                                       \u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.0961, valid_loss=97.40]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0923, train_loss_epoch=0.0923, valid_loss=97.40]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=97.40]        \n",
      "Epoch 514: 100%|██████████| 1/1 [00:00<00:00, 76.18it/s, v_num=2587929, train_loss_step=0.0803, train_loss_epoch=0.0824, valid_loss=97.40]\n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0803, train_loss_epoch=0.0803, valid_loss=97.40]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0818, train_loss_epoch=0.0818, valid_loss=97.40]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0705, train_loss_epoch=0.0705, valid_loss=97.40]        \n",
      "Epoch 536: 100%|██████████| 1/1 [00:00<00:00, 74.56it/s, v_num=2587929, train_loss_step=0.0685, train_loss_epoch=0.0685, valid_loss=97.40]\n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0685, train_loss_epoch=0.0685, valid_loss=97.40]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0562, train_loss_epoch=0.0562, valid_loss=97.40]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=97.40]          \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=97.40]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=97.40]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=97.40]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=97.40]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0642, train_loss_epoch=0.0642, valid_loss=97.40]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=97.40]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.070, train_loss_epoch=0.070, valid_loss=97.40]          \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=97.40]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 76.01it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0661, valid_loss=97.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.25it/s]\u001b[A\n",
      "Epoch 601: 100%|██████████| 1/1 [00:00<00:00, 75.87it/s, v_num=2587929, train_loss_step=0.0808, train_loss_epoch=0.0808, valid_loss=104.0]\n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=104.0]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=104.0]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=104.0]        \n",
      "Epoch 616: 100%|██████████| 1/1 [00:00<00:00, 74.79it/s, v_num=2587929, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=104.0]\n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0715, train_loss_epoch=0.0715, valid_loss=104.0]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=104.0]          \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=104.0]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0721, train_loss_epoch=0.0721, valid_loss=104.0]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=104.0]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0571, train_loss_epoch=0.0571, valid_loss=104.0]        \n",
      "Epoch 660: 100%|██████████| 1/1 [00:00<00:00, 74.28it/s, v_num=2587929, train_loss_step=0.0833, train_loss_epoch=0.0833, valid_loss=104.0]\n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0833, train_loss_epoch=0.0833, valid_loss=104.0]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=104.0]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=104.0]          \n",
      "Epoch 675: 100%|██████████| 1/1 [00:00<00:00, 74.08it/s, v_num=2587929, train_loss_step=0.0531, train_loss_epoch=0.054, valid_loss=104.0]\n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0531, train_loss_epoch=0.0531, valid_loss=104.0]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=104.0]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=104.0]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=104.0]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 75.28it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.79it/s]\u001b[A\n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=79.10]          \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=79.10]        \n",
      "Epoch 718: 100%|██████████| 1/1 [00:00<00:00, 73.05it/s, v_num=2587929, train_loss_step=0.0588, train_loss_epoch=0.0588, valid_loss=79.10]\n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0588, train_loss_epoch=0.0588, valid_loss=79.10]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0588, train_loss_epoch=0.0588, valid_loss=79.10]\n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=79.10]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=79.10]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0567, train_loss_epoch=0.0567, valid_loss=79.10]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0749, train_loss_epoch=0.0749, valid_loss=79.10]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.057, train_loss_epoch=0.057, valid_loss=79.10]          \n",
      "Epoch 755: 100%|██████████| 1/1 [00:00<00:00, 74.70it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=79.10]\n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=79.10]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=79.10]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=79.10]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=79.10]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=79.10]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=79.10]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=79.10]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=79.10]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=79.10]\n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 75.36it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0497, valid_loss=79.10]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.16it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=515532)\u001b[0m \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0521, train_loss_epoch=0.0521, valid_loss=88.90]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=88.90]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=88.90]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0668, train_loss_epoch=0.0668, valid_loss=88.90]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0622, train_loss_epoch=0.0622, valid_loss=88.90]        \n",
      "Epoch 835: 100%|██████████| 1/1 [00:00<00:00, 73.22it/s, v_num=2587929, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=88.90]  \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=88.90]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0687, train_loss_epoch=0.0687, valid_loss=88.90]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=88.90]        \n",
      "Epoch 850: 100%|██████████| 1/1 [00:00<00:00, 74.22it/s, v_num=2587929, train_loss_step=0.0561, train_loss_epoch=0.0505, valid_loss=88.90]\n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0561, train_loss_epoch=0.0561, valid_loss=88.90]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0734, train_loss_epoch=0.0734, valid_loss=88.90]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0693, train_loss_epoch=0.0693, valid_loss=88.90]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0542, train_loss_epoch=0.0542, valid_loss=88.90]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.068, train_loss_epoch=0.068, valid_loss=88.90]          \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=88.90]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=88.90]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0521, train_loss_epoch=0.0521, valid_loss=88.90]        \n",
      "Epoch 894: 100%|██████████| 1/1 [00:00<00:00, 72.44it/s, v_num=2587929, train_loss_step=0.0604, train_loss_epoch=0.0604, valid_loss=88.90]\n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0604, train_loss_epoch=0.0604, valid_loss=88.90]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 73.31it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0572, valid_loss=88.90]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.09it/s]\u001b[A\n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0604, train_loss_epoch=0.0604, valid_loss=104.0]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=104.0]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.056, train_loss_epoch=0.056, valid_loss=104.0]          \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=104.0]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0475, train_loss_epoch=0.0475, valid_loss=104.0]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0451, train_loss_epoch=0.0451, valid_loss=104.0]        \n",
      "Epoch 937: 100%|██████████| 1/1 [00:00<00:00, 74.18it/s, v_num=2587929, train_loss_step=0.0433, train_loss_epoch=0.0508, valid_loss=104.0]\n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=104.0]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=104.0]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=104.0]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=104.0]          \n",
      "Epoch 959: 100%|██████████| 1/1 [00:00<00:00, 76.98it/s, v_num=2587929, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=104.0]\n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0886, train_loss_epoch=0.0886, valid_loss=104.0]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0772, train_loss_epoch=0.0772, valid_loss=104.0]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=104.0]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=104.0]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=104.0]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=104.0]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 75.23it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0556, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.24it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 37.02it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=85.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=515532)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m /home/hmf6av/.local/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m [rank: 0] Seed set to 1\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 0 | loss            | MAE           | 0      | train\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 4 | context_adapter | Linear        | 8.0 K  | train\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 494 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 494 K     Total params\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 1.978     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.560, train_loss_epoch=3.560]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.200, train_loss_epoch=3.200]        \n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 73.61it/s, v_num=2587929, train_loss_step=3.120, train_loss_epoch=3.120]\n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.280, train_loss_epoch=2.280]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.540, train_loss_epoch=1.540]        \n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 73.92it/s, v_num=2587929, train_loss_step=1.250, train_loss_epoch=1.250]\n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.250, train_loss_epoch=1.250]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.952, train_loss_epoch=0.952]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.932, train_loss_epoch=0.932]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.822, train_loss_epoch=0.822]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.700, train_loss_epoch=0.700]        \n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 73.68it/s, v_num=2587929, train_loss_step=0.653, train_loss_epoch=0.653]\n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.653, train_loss_epoch=0.653]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.527, train_loss_epoch=0.527]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.529, train_loss_epoch=0.529]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.473, train_loss_epoch=0.473]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 76.12it/s, v_num=2587929, train_loss_step=0.418, train_loss_epoch=0.450]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.41it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=677.0]       \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=677.0]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=677.0]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=677.0]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=677.0]\n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=677.0]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=677.0]        \n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 75.76it/s, v_num=2587929, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=677.0]\n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=677.0]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=677.0]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=677.0]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=677.0]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=677.0]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=677.0]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=677.0]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=677.0]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=677.0]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=677.0]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=677.0]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 75.90it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.174, valid_loss=677.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.47it/s]\u001b[A\n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=159.0]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=159.0]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=159.0]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=159.0]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=159.0]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=159.0]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=159.0]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=159.0]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=159.0]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=159.0]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=159.0]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=159.0]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=159.0]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=159.0]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=159.0]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=159.0]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 76.12it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.0989, valid_loss=159.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.07it/s]\u001b[A\n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=113.0]          \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0984, train_loss_epoch=0.0984, valid_loss=113.0]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=113.0]          \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=113.0]          \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=113.0]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=113.0]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0952, train_loss_epoch=0.0952, valid_loss=113.0]        \n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 74.52it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=113.0]  \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=113.0]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=113.0]          \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0988, train_loss_epoch=0.0988, valid_loss=113.0]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0938, train_loss_epoch=0.0938, valid_loss=113.0]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=113.0]          \n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 74.72it/s, v_num=2587929, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=113.0]\n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=113.0]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=113.0]          \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=113.0]          \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0974, train_loss_epoch=0.0974, valid_loss=113.0]        \n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 76.12it/s, v_num=2587929, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=113.0]  \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=113.0]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 77.26it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.55it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=112.0]        \n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 73.18it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=112.0]  \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=112.0]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=112.0]          \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0957, train_loss_epoch=0.0957, valid_loss=112.0]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=112.0]          \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=112.0]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0791, train_loss_epoch=0.0791, valid_loss=112.0]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=112.0]          \n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 73.38it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=112.0]\n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=112.0]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0983, train_loss_epoch=0.0983, valid_loss=112.0]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=112.0]          \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=112.0]          \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0954, train_loss_epoch=0.0954, valid_loss=112.0]        \n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 75.30it/s, v_num=2587929, train_loss_step=0.0954, train_loss_epoch=0.0954, valid_loss=112.0]\n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=112.0]          \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0998, train_loss_epoch=0.0998, valid_loss=112.0]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 77.12it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.090, valid_loss=112.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.35it/s]\u001b[A\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=97.40]          \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0984, train_loss_epoch=0.0984, valid_loss=97.40]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0894, train_loss_epoch=0.0894, valid_loss=97.40]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=97.40]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0752, train_loss_epoch=0.0752, valid_loss=97.40]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0592, train_loss_epoch=0.0592, valid_loss=97.40]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0581, train_loss_epoch=0.0581, valid_loss=97.40]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0558, train_loss_epoch=0.0558, valid_loss=97.40]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=97.40]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=97.40]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0597, train_loss_epoch=0.0597, valid_loss=97.40]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=97.40]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=97.40]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=97.40]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 76.00it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0661, valid_loss=97.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.02it/s]\u001b[A\n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 38.04it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0761, valid_loss=104.0]\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0761, valid_loss=104.0]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=104.0]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=104.0]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=104.0]\n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0568, train_loss_epoch=0.0568, valid_loss=104.0]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=104.0]        \n",
      "Epoch 629: 100%|██████████| 1/1 [00:00<00:00, 78.71it/s, v_num=2587929, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=104.0]\n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=104.0]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0601, train_loss_epoch=0.0601, valid_loss=104.0]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=104.0]        \n",
      "Epoch 644: 100%|██████████| 1/1 [00:00<00:00, 74.73it/s, v_num=2587929, train_loss_step=0.0528, train_loss_epoch=0.0672, valid_loss=104.0]\n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0528, train_loss_epoch=0.0528, valid_loss=104.0]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=104.0]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0745, train_loss_epoch=0.0745, valid_loss=104.0]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=104.0]          \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0561, train_loss_epoch=0.0561, valid_loss=104.0]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=104.0]          \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=104.0]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.045, train_loss_epoch=0.045, valid_loss=104.0]          \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=104.0]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 77.03it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.28it/s]\u001b[A\n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0707, train_loss_epoch=0.0707, valid_loss=79.10]        \n",
      "Epoch 710: 100%|██████████| 1/1 [00:00<00:00, 74.65it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=79.10]\n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=79.10]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=79.10]        \n",
      "Epoch 725: 100%|██████████| 1/1 [00:00<00:00, 75.62it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=79.10]\n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=79.10]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=79.10]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0586, train_loss_epoch=0.0586, valid_loss=79.10]        \n",
      "Epoch 740: 100%|██████████| 1/1 [00:00<00:00, 78.29it/s, v_num=2587929, train_loss_step=0.0586, train_loss_epoch=0.0586, valid_loss=79.10]\n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0749, train_loss_epoch=0.0749, valid_loss=79.10]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.057, train_loss_epoch=0.057, valid_loss=79.10]          \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=79.10]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=79.10]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=79.10]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=79.10]        \n",
      "Epoch 770: 100%|██████████| 1/1 [00:00<00:00, 74.60it/s, v_num=2587929, train_loss_step=0.0649, train_loss_epoch=0.0594, valid_loss=79.10]\n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=79.10]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=79.10]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=79.10]        \n",
      "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 75.43it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0582, valid_loss=79.10]\n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=79.10]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=79.10]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 76.58it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0497, valid_loss=79.10]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.98it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=515629)\u001b[0m \n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0512, valid_loss=88.90]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0585, train_loss_epoch=0.0585, valid_loss=88.90]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=88.90]        \n",
      "Epoch 814: 100%|██████████| 1/1 [00:00<00:00, 76.15it/s, v_num=2587929, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=88.90]  \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=88.90]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0703, train_loss_epoch=0.0703, valid_loss=88.90]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=88.90]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=88.90]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0626, train_loss_epoch=0.0626, valid_loss=88.90]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=88.90]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0599, train_loss_epoch=0.0599, valid_loss=88.90]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=88.90]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.058, train_loss_epoch=0.058, valid_loss=88.90]          \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=88.90]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0685, train_loss_epoch=0.0685, valid_loss=88.90]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=88.90]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=88.90]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=88.90]        \n",
      "Epoch 889: 100%|██████████| 1/1 [00:00<00:00, 78.31it/s, v_num=2587929, train_loss_step=0.0587, train_loss_epoch=0.0587, valid_loss=88.90]\n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=88.90]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=88.90]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 76.38it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0572, valid_loss=88.90]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.61it/s]\u001b[A\n",
      "Epoch 903: 100%|██████████| 1/1 [00:00<00:00, 74.90it/s, v_num=2587929, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=104.0]\n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=104.0]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=104.0]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0507, train_loss_epoch=0.0507, valid_loss=104.0]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=104.0]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=104.0]          \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0554, train_loss_epoch=0.0554, valid_loss=104.0]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=104.0]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0941, train_loss_epoch=0.0941, valid_loss=104.0]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=104.0]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=104.0]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=104.0]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0861, train_loss_epoch=0.0861, valid_loss=104.0]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0799, train_loss_epoch=0.0799, valid_loss=104.0]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=104.0]        \n",
      "Epoch 993: 100%|██████████| 1/1 [00:00<00:00, 76.22it/s, v_num=2587929, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=104.0]\n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=104.0]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 77.33it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0556, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=515629)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=515629)\u001b[0m \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=85.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=515792)\u001b[0m /home/hmf6av/.local/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m [rank: 0] Seed set to 1\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 0 | loss            | MAE           | 0      | train\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 4 | context_adapter | Linear        | 8.0 K  | train\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 494 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 494 K     Total params\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 1.978     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.600, train_loss_epoch=3.600]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.340, train_loss_epoch=3.340]       \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.670, train_loss_epoch=2.670]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.810, train_loss_epoch=1.810]        \n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 76.20it/s, v_num=2587929, train_loss_step=1.340, train_loss_epoch=1.400]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.340, train_loss_epoch=1.340]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.885, train_loss_epoch=0.885]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.777, train_loss_epoch=0.777]        \n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 75.81it/s, v_num=2587929, train_loss_step=0.643, train_loss_epoch=0.643]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.633, train_loss_epoch=0.633]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.564, train_loss_epoch=0.564]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.495, train_loss_epoch=0.495]        \n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 75.39it/s, v_num=2587929, train_loss_step=0.466, train_loss_epoch=0.524]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.466, train_loss_epoch=0.466]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.464, train_loss_epoch=0.464]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 75.76it/s, v_num=2587929, train_loss_step=0.418, train_loss_epoch=0.450]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.63it/s]\u001b[A\n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=677.0]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=677.0]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=677.0]        \n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 72.17it/s, v_num=2587929, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=677.0]\n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=677.0]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=677.0]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=677.0]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=677.0]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=677.0]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=677.0]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=677.0]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=677.0]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=677.0]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=677.0]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=677.0]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=677.0]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=677.0]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=677.0]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 73.40it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.174, valid_loss=677.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.70it/s]\u001b[A\n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=159.0]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=159.0]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=159.0]        \n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 73.20it/s, v_num=2587929, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=159.0]\n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=159.0]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=159.0]\n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=159.0]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=159.0]        \n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 72.56it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=159.0]\n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=159.0]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=159.0]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=159.0]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=159.0]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=159.0]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=159.0]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=159.0]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=159.0]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=159.0]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 75.82it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.0989, valid_loss=159.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.69it/s]\u001b[A\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 74.18it/s, v_num=2587929, train_loss_step=0.0984, train_loss_epoch=0.0984, valid_loss=113.0]\n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0984, train_loss_epoch=0.0984, valid_loss=113.0]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=113.0]          \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=113.0]          \n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 71.45it/s, v_num=2587929, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=113.0]\n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=113.0]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0952, train_loss_epoch=0.0952, valid_loss=113.0]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=113.0]          \n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 75.68it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=113.0]\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 74.65it/s, v_num=2587929, train_loss_step=0.120, train_loss_epoch=0.104, valid_loss=113.0]\n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=113.0]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0988, train_loss_epoch=0.0988, valid_loss=113.0]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0938, train_loss_epoch=0.0938, valid_loss=113.0]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=113.0]          \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=113.0]          \n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 72.47it/s, v_num=2587929, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=113.0]\n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=113.0]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=113.0]          \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0919, train_loss_epoch=0.0919, valid_loss=113.0]        \n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 74.88it/s, v_num=2587929, train_loss_step=0.0974, train_loss_epoch=0.0919, valid_loss=113.0]\n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0974, train_loss_epoch=0.0974, valid_loss=113.0]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=113.0]          \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 74.44it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.57it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0937, train_loss_epoch=0.0937, valid_loss=112.0]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0944, train_loss_epoch=0.0944, valid_loss=112.0]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0965, train_loss_epoch=0.0965, valid_loss=112.0]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0884, train_loss_epoch=0.0884, valid_loss=112.0]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0922, train_loss_epoch=0.0922, valid_loss=112.0]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=112.0]          \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=112.0]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0911, train_loss_epoch=0.0911, valid_loss=112.0]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=112.0]          \n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 77.05it/s, v_num=2587929, train_loss_step=0.120, train_loss_epoch=0.103, valid_loss=112.0]\n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=112.0]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=112.0]          \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=112.0]          \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=112.0]        \n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 76.11it/s, v_num=2587929, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=112.0]\n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=112.0]          \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0854, train_loss_epoch=0.0854, valid_loss=112.0]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=112.0]          \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 74.71it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.090, valid_loss=112.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.28it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.0961, valid_loss=97.40]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0863, train_loss_epoch=0.0863, valid_loss=97.40]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0998, train_loss_epoch=0.0998, valid_loss=97.40]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0803, train_loss_epoch=0.0803, valid_loss=97.40]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0818, train_loss_epoch=0.0818, valid_loss=97.40]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0727, train_loss_epoch=0.0727, valid_loss=97.40]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0685, train_loss_epoch=0.0685, valid_loss=97.40]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0562, train_loss_epoch=0.0562, valid_loss=97.40]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=97.40]          \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=97.40]        \n",
      "Epoch 565: 100%|██████████| 1/1 [00:00<00:00, 74.86it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=97.40]\n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=97.40]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=97.40]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0642, train_loss_epoch=0.0642, valid_loss=97.40]        \n",
      "Epoch 587: 100%|██████████| 1/1 [00:00<00:00, 76.24it/s, v_num=2587929, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=97.40]\n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.070, train_loss_epoch=0.070, valid_loss=97.40]          \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=97.40]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 77.94it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0661, valid_loss=97.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.85it/s]\u001b[A\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0808, train_loss_epoch=0.0808, valid_loss=104.0]        \n",
      "Epoch 601: 100%|██████████| 1/1 [00:00<00:00, 71.39it/s, v_num=2587929, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=104.0]\n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=104.0]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=104.0]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=104.0]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=104.0]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=104.0]          \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=104.0]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0721, train_loss_epoch=0.0721, valid_loss=104.0]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0528, train_loss_epoch=0.0528, valid_loss=104.0]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=104.0]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0571, train_loss_epoch=0.0571, valid_loss=104.0]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0745, train_loss_epoch=0.0745, valid_loss=104.0]        \n",
      "Epoch 667: 100%|██████████| 1/1 [00:00<00:00, 75.06it/s, v_num=2587929, train_loss_step=0.0653, train_loss_epoch=0.075, valid_loss=104.0] \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=104.0]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=104.0]          \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=104.0]        \n",
      "Epoch 682: 100%|██████████| 1/1 [00:00<00:00, 74.18it/s, v_num=2587929, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=104.0]\n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=104.0]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=104.0]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=104.0]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 75.01it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.13it/s]\u001b[A\n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=79.10]          \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=79.10]\n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=79.10]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=79.10]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0588, train_loss_epoch=0.0588, valid_loss=79.10]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=79.10]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=79.10]        \n",
      "Epoch 740: 100%|██████████| 1/1 [00:00<00:00, 75.92it/s, v_num=2587929, train_loss_step=0.0749, train_loss_epoch=0.0586, valid_loss=79.10]\n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0749, train_loss_epoch=0.0749, valid_loss=79.10]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.057, train_loss_epoch=0.057, valid_loss=79.10]          \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=79.10]        \n",
      "Epoch 762: 100%|██████████| 1/1 [00:00<00:00, 74.08it/s, v_num=2587929, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=79.10]\n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=79.10]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=79.10]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.065, train_loss_epoch=0.065, valid_loss=79.10]          \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=79.10]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=79.10]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=79.10]        \n",
      "Epoch 792: 100%|██████████| 1/1 [00:00<00:00, 77.02it/s, v_num=2587929, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=79.10]\n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=79.10]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 75.50it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0497, valid_loss=79.10]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.93it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=515792)\u001b[0m \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0521, train_loss_epoch=0.0521, valid_loss=88.90]        \n",
      "Epoch 806: 100%|██████████| 1/1 [00:00<00:00, 71.75it/s, v_num=2587929, train_loss_step=0.0585, train_loss_epoch=0.0585, valid_loss=88.90]\n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0585, train_loss_epoch=0.0585, valid_loss=88.90]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=88.90]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=88.90]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0668, train_loss_epoch=0.0668, valid_loss=88.90]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=88.90]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=88.90]          \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0687, train_loss_epoch=0.0687, valid_loss=88.90]        \n",
      "Epoch 843: 100%|██████████| 1/1 [00:00<00:00, 75.72it/s, v_num=2587929, train_loss_step=0.0687, train_loss_epoch=0.0687, valid_loss=88.90]\n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=88.90]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0561, train_loss_epoch=0.0561, valid_loss=88.90]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0734, train_loss_epoch=0.0734, valid_loss=88.90]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0637, train_loss_epoch=0.0637, valid_loss=88.90]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.068, train_loss_epoch=0.068, valid_loss=88.90]          \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=88.90]        \n",
      "Epoch 887: 100%|██████████| 1/1 [00:00<00:00, 75.02it/s, v_num=2587929, train_loss_step=0.0449, train_loss_epoch=0.0516, valid_loss=88.90]\n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0449, train_loss_epoch=0.0449, valid_loss=88.90]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0604, train_loss_epoch=0.0604, valid_loss=88.90]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 75.44it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0572, valid_loss=88.90]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.10it/s]\u001b[A\n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0604, train_loss_epoch=0.0604, valid_loss=104.0]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=104.0]        \n",
      "Epoch 908: 100%|██████████| 1/1 [00:00<00:00, 72.62it/s, v_num=2587929, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=104.0]\n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=104.0]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=104.0]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0475, train_loss_epoch=0.0475, valid_loss=104.0]        \n",
      "Epoch 923: 100%|██████████| 1/1 [00:00<00:00, 73.77it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0549, valid_loss=104.0]\n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0549, valid_loss=104.0]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=104.0]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=104.0]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=104.0]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0441, train_loss_epoch=0.0441, valid_loss=104.0]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0531, train_loss_epoch=0.0531, valid_loss=104.0]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0886, train_loss_epoch=0.0886, valid_loss=104.0]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0772, train_loss_epoch=0.0772, valid_loss=104.0]        \n",
      "Epoch 974: 100%|██████████| 1/1 [00:00<00:00, 75.13it/s, v_num=2587929, train_loss_step=0.0656, train_loss_epoch=0.0882, valid_loss=104.0]\n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=104.0]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=104.0]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=104.0]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=104.0]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0431, train_loss_epoch=0.0431, valid_loss=104.0]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 72.86it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0556, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.57it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 34.80it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=85.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=515792)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m /home/hmf6av/.local/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m [rank: 0] Seed set to 1\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 0 | loss            | MAE           | 0      | train\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 4 | context_adapter | Linear        | 8.0 K  | train\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 494 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 494 K     Total params\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 1.978     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.530, train_loss_epoch=3.530]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 76.00it/s, v_num=2587929, train_loss_step=3.020, train_loss_epoch=3.120]\n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.020, train_loss_epoch=3.020]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.150, train_loss_epoch=2.150]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.500, train_loss_epoch=1.500]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.480, train_loss_epoch=1.480]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.932, train_loss_epoch=0.932]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.915, train_loss_epoch=0.915]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.801, train_loss_epoch=0.801]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.700, train_loss_epoch=0.700]        \n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 76.24it/s, v_num=2587929, train_loss_step=0.700, train_loss_epoch=0.700]\n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.710, train_loss_epoch=0.710]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.653, train_loss_epoch=0.653]        \n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 67.51it/s, v_num=2587929, train_loss_step=0.582, train_loss_epoch=0.582]\n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.582, train_loss_epoch=0.582]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.529, train_loss_epoch=0.529]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.454, train_loss_epoch=0.454]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 75.04it/s, v_num=2587929, train_loss_step=0.418, train_loss_epoch=0.450]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.07it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=677.0]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=677.0]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=677.0]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=677.0]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=677.0]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=677.0]        \n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 77.59it/s, v_num=2587929, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=677.0]\n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=677.0]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=677.0]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=677.0]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=677.0]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=677.0]        \n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 74.97it/s, v_num=2587929, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=677.0]\n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=677.0]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=677.0]        \n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 74.70it/s, v_num=2587929, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=677.0]\n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=677.0]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 76.59it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.174, valid_loss=677.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.54it/s]\u001b[A\n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=159.0]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=159.0]        \n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 75.28it/s, v_num=2587929, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=159.0]\n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=159.0]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=159.0]        \n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 75.52it/s, v_num=2587929, train_loss_step=0.183, train_loss_epoch=0.141, valid_loss=159.0]\n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=159.0]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=159.0]        \n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 75.47it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=159.0]\n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=159.0]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=159.0]        \n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 73.33it/s, v_num=2587929, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=159.0]\n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=159.0]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=159.0]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=159.0]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=159.0]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=159.0]        \n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 77.05it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=159.0]\n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=159.0]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=159.0]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 77.47it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.0989, valid_loss=159.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.93it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=113.0]         \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=113.0]          \n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 75.18it/s, v_num=2587929, train_loss_step=0.0942, train_loss_epoch=0.0942, valid_loss=113.0]\n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0942, train_loss_epoch=0.0942, valid_loss=113.0]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.092, train_loss_epoch=0.092, valid_loss=113.0]          \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0978, train_loss_epoch=0.0978, valid_loss=113.0]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0876, train_loss_epoch=0.0876, valid_loss=113.0]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0848, train_loss_epoch=0.0848, valid_loss=113.0]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]          \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=113.0]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0947, train_loss_epoch=0.0947, valid_loss=113.0]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0897, train_loss_epoch=0.0897, valid_loss=113.0]        \n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 74.75it/s, v_num=2587929, train_loss_step=0.0971, train_loss_epoch=0.0971, valid_loss=113.0]\n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0971, train_loss_epoch=0.0971, valid_loss=113.0]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=113.0]          \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=113.0]          \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=113.0]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0982, train_loss_epoch=0.0982, valid_loss=113.0]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0897, train_loss_epoch=0.0897, valid_loss=113.0]        \n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 72.59it/s, v_num=2587929, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=113.0]  \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=113.0]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=113.0]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 76.36it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.89it/s]\u001b[A\n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=112.0]          \n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 75.43it/s, v_num=2587929, train_loss_step=0.0868, train_loss_epoch=0.104, valid_loss=112.0]\n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0868, train_loss_epoch=0.0868, valid_loss=112.0]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.093, train_loss_epoch=0.093, valid_loss=112.0]          \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=112.0]          \n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 77.35it/s, v_num=2587929, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=112.0]\n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=112.0]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0801, train_loss_epoch=0.0801, valid_loss=112.0]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0916, train_loss_epoch=0.0916, valid_loss=112.0]        \n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 73.54it/s, v_num=2587929, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=112.0]  \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=112.0]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=112.0]          \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=112.0]          \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.084, train_loss_epoch=0.084, valid_loss=112.0]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=112.0]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0962, train_loss_epoch=0.0962, valid_loss=112.0]        \n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 72.36it/s, v_num=2587929, train_loss_step=0.0866, train_loss_epoch=0.0866, valid_loss=112.0]\n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0866, train_loss_epoch=0.0866, valid_loss=112.0]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=112.0]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0782, train_loss_epoch=0.0782, valid_loss=112.0]        \n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 73.58it/s, v_num=2587929, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=112.0]  \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=112.0]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0999, train_loss_epoch=0.0999, valid_loss=112.0]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 76.90it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.090, valid_loss=112.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.43it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=515902)\u001b[0m \n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.0961, valid_loss=97.40]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0923, train_loss_epoch=0.0923, valid_loss=97.40]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=97.40]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0803, train_loss_epoch=0.0803, valid_loss=97.40]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0818, train_loss_epoch=0.0818, valid_loss=97.40]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0705, train_loss_epoch=0.0705, valid_loss=97.40]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=97.40]        \n",
      "Epoch 536: 100%|██████████| 1/1 [00:00<00:00, 72.43it/s, v_num=2587929, train_loss_step=0.0685, train_loss_epoch=0.0685, valid_loss=97.40]\n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0685, train_loss_epoch=0.0685, valid_loss=97.40]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0562, train_loss_epoch=0.0562, valid_loss=97.40]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=97.40]          \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=97.40]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=97.40]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=97.40]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=97.40]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0606, train_loss_epoch=0.0606, valid_loss=97.40]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=97.40]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.070, train_loss_epoch=0.070, valid_loss=97.40]          \n",
      "Epoch 595: 100%|██████████| 1/1 [00:00<00:00, 76.98it/s, v_num=2587929, train_loss_step=0.0787, train_loss_epoch=0.0552, valid_loss=97.40]\n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0787, train_loss_epoch=0.0787, valid_loss=97.40]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 76.53it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0661, valid_loss=97.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.41it/s]\u001b[A\n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=104.0]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=104.0]        \n",
      "Epoch 609: 100%|██████████| 1/1 [00:00<00:00, 75.32it/s, v_num=2587929, train_loss_step=0.0606, train_loss_epoch=0.0606, valid_loss=104.0]\n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0606, train_loss_epoch=0.0606, valid_loss=104.0]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0715, train_loss_epoch=0.0715, valid_loss=104.0]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=104.0]          \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=104.0]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=104.0]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0535, train_loss_epoch=0.0535, valid_loss=104.0]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0689, train_loss_epoch=0.0689, valid_loss=104.0]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0603, train_loss_epoch=0.0603, valid_loss=104.0]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0833, train_loss_epoch=0.0833, valid_loss=104.0]        \n",
      "Epoch 661: 100%|██████████| 1/1 [00:00<00:00, 72.17it/s, v_num=2587929, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=104.0]\n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=104.0]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0596, train_loss_epoch=0.0596, valid_loss=104.0]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0531, train_loss_epoch=0.0531, valid_loss=104.0]        \n",
      "Epoch 683: 100%|██████████| 1/1 [00:00<00:00, 75.08it/s, v_num=2587929, train_loss_step=0.0608, train_loss_epoch=0.0658, valid_loss=104.0]\n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=104.0]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=104.0]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=104.0]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 76.35it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.74it/s]\u001b[A\n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=79.10]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0586, train_loss_epoch=0.0586, valid_loss=79.10]        \n",
      "Epoch 719: 100%|██████████| 1/1 [00:00<00:00, 75.27it/s, v_num=2587929, train_loss_step=0.0707, train_loss_epoch=0.0588, valid_loss=79.10]\n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0707, train_loss_epoch=0.0707, valid_loss=79.10]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=79.10]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0567, train_loss_epoch=0.0567, valid_loss=79.10]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0749, train_loss_epoch=0.0749, valid_loss=79.10]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0752, train_loss_epoch=0.0752, valid_loss=79.10]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.067, train_loss_epoch=0.067, valid_loss=79.10]          \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=79.10]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=79.10]        \n",
      "Epoch 763: 100%|██████████| 1/1 [00:00<00:00, 73.09it/s, v_num=2587929, train_loss_step=0.0581, train_loss_epoch=0.0581, valid_loss=79.10]\n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0581, train_loss_epoch=0.0581, valid_loss=79.10]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=79.10]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=79.10]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0588, train_loss_epoch=0.0588, valid_loss=79.10]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=79.10]        \n",
      "Epoch 793: 100%|██████████| 1/1 [00:00<00:00, 77.18it/s, v_num=2587929, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=79.10]\n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=79.10]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 73.92it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0497, valid_loss=79.10]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.11it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0512, valid_loss=88.90]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0585, train_loss_epoch=0.0585, valid_loss=88.90]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=88.90]          \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=88.90]\n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0703, train_loss_epoch=0.0703, valid_loss=88.90]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=88.90]        \n",
      "Epoch 829: 100%|██████████| 1/1 [00:00<00:00, 76.29it/s, v_num=2587929, train_loss_step=0.0628, train_loss_epoch=0.0634, valid_loss=88.90]\n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=88.90]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0626, train_loss_epoch=0.0626, valid_loss=88.90]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=88.90]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0599, train_loss_epoch=0.0599, valid_loss=88.90]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=88.90]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.058, train_loss_epoch=0.058, valid_loss=88.90]          \n",
      "Epoch 859: 100%|██████████| 1/1 [00:00<00:00, 74.60it/s, v_num=2587929, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=88.90]\n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=88.90]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0685, train_loss_epoch=0.0685, valid_loss=88.90]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=88.90]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=88.90]        \n",
      "Epoch 889: 100%|██████████| 1/1 [00:00<00:00, 76.20it/s, v_num=2587929, train_loss_step=0.0522, train_loss_epoch=0.0587, valid_loss=88.90]\n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=88.90]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=88.90]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 75.13it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0572, valid_loss=88.90]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.69it/s]\u001b[A\n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0554, train_loss_epoch=0.0554, valid_loss=104.0]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=104.0]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=104.0]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0467, train_loss_epoch=0.0467, valid_loss=104.0]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0507, train_loss_epoch=0.0507, valid_loss=104.0]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=104.0]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0485, train_loss_epoch=0.0485, valid_loss=104.0]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=104.0]          \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0554, train_loss_epoch=0.0554, valid_loss=104.0]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=104.0]          \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=104.0]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0941, train_loss_epoch=0.0941, valid_loss=104.0]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=104.0]        \n",
      "Epoch 970: 100%|██████████| 1/1 [00:00<00:00, 74.06it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0791, valid_loss=104.0]\n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=104.0]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0861, train_loss_epoch=0.0861, valid_loss=104.0]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0572, train_loss_epoch=0.0572, valid_loss=104.0]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=104.0]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=104.0]\n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0542, train_loss_epoch=0.0542, valid_loss=104.0]        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=515902)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 77.56it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0556, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.40it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 36.91it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=85.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=516035)\u001b[0m /home/hmf6av/.local/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m [rank: 0] Seed set to 1\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 0 | loss            | MAE           | 0      | train\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 4 | context_adapter | Linear        | 8.0 K  | train\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 494 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 494 K     Total params\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 1.978     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.530, train_loss_epoch=3.530]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.500, train_loss_epoch=3.500]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.020, train_loss_epoch=3.020]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.150, train_loss_epoch=2.150]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.480, train_loss_epoch=1.480]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 73.23it/s, v_num=2587929, train_loss_step=0.915, train_loss_epoch=0.915]\n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.915, train_loss_epoch=0.915]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.801, train_loss_epoch=0.801]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.700, train_loss_epoch=0.700]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.653, train_loss_epoch=0.653]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.582, train_loss_epoch=0.582]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.529, train_loss_epoch=0.529]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.454, train_loss_epoch=0.454]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 78.36it/s, v_num=2587929, train_loss_step=0.418, train_loss_epoch=0.450]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.46it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=677.0]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=677.0]        \n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 78.93it/s, v_num=2587929, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=677.0]\n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=677.0]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=677.0]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=677.0]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=677.0]        \n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 72.47it/s, v_num=2587929, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=677.0]\n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=677.0]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=677.0]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=677.0]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=677.0]        \n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 75.59it/s, v_num=2587929, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=677.0]\n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=677.0]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=677.0]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=677.0]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=677.0]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=677.0]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=677.0]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=677.0]        \n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 72.73it/s, v_num=2587929, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=677.0]\n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=677.0]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 73.59it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.174, valid_loss=677.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.09it/s]\u001b[A\n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=159.0]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=159.0]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=159.0]        \n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 74.90it/s, v_num=2587929, train_loss_step=0.141, train_loss_epoch=0.156, valid_loss=159.0]\n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=159.0]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=159.0]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=159.0]        \n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 73.14it/s, v_num=2587929, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=159.0]\n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=159.0]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=159.0]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=159.0]        \n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 75.28it/s, v_num=2587929, train_loss_step=0.138, train_loss_epoch=0.132, valid_loss=159.0]\n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=159.0]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=159.0]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=159.0]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=159.0]        \n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 72.64it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=159.0]\n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=159.0]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=159.0]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=159.0]        \n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 74.12it/s, v_num=2587929, train_loss_step=0.0989, train_loss_epoch=0.0989, valid_loss=159.0]\n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0989, train_loss_epoch=0.0989, valid_loss=159.0]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 75.06it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.0989, valid_loss=159.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.39it/s]\u001b[A\n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0984, train_loss_epoch=0.0984, valid_loss=113.0]        \n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 75.67it/s, v_num=2587929, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=113.0]  \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=113.0]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=113.0]          \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=113.0]        \n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 74.02it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.0952, valid_loss=113.0] \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=113.0]         \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=113.0]          \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0988, train_loss_epoch=0.0988, valid_loss=113.0]        \n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 74.10it/s, v_num=2587929, train_loss_step=0.0857, train_loss_epoch=0.0857, valid_loss=113.0]\n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0857, train_loss_epoch=0.0857, valid_loss=113.0]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=113.0]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=113.0]          \n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 73.65it/s, v_num=2587929, train_loss_step=0.0966, train_loss_epoch=0.0966, valid_loss=113.0]\n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0966, train_loss_epoch=0.0966, valid_loss=113.0]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=113.0]          \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0974, train_loss_epoch=0.0974, valid_loss=113.0]        \n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 76.74it/s, v_num=2587929, train_loss_step=0.0974, train_loss_epoch=0.0974, valid_loss=113.0]\n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0855, train_loss_epoch=0.0855, valid_loss=113.0]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=113.0]          \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 75.11it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.98it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=112.0]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0944, train_loss_epoch=0.0944, valid_loss=112.0]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=112.0]          \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=112.0]          \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0957, train_loss_epoch=0.0957, valid_loss=112.0]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=112.0]          \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=112.0]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0894, train_loss_epoch=0.0894, valid_loss=112.0]        \n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 76.56it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.093, valid_loss=112.0]  \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=112.0]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=112.0]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=112.0]          \n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 72.55it/s, v_num=2587929, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=112.0]  \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=112.0]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0698, train_loss_epoch=0.0698, valid_loss=112.0]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=112.0]          \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=112.0]          \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 76.58it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.090, valid_loss=112.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.36it/s]\u001b[A\n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0996, train_loss_epoch=0.0996, valid_loss=97.40]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0918, train_loss_epoch=0.0918, valid_loss=97.40]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=97.40]          \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=97.40]          \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0837, train_loss_epoch=0.0837, valid_loss=97.40]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=97.40]          \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=97.40]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0626, train_loss_epoch=0.0626, valid_loss=97.40]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=97.40]          \n",
      "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 76.16it/s, v_num=2587929, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=97.40]\n",
      "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 75.09it/s, v_num=2587929, train_loss_step=0.0645, train_loss_epoch=0.0669, valid_loss=97.40]\n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=97.40]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=97.40]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=97.40]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=97.40]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=97.40]\n",
      "Epoch 589: 100%|██████████| 1/1 [00:00<00:00, 67.31it/s, v_num=2587929, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=97.40]\n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=97.40]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0603, train_loss_epoch=0.0603, valid_loss=97.40]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 75.71it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0661, valid_loss=97.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.94it/s]\u001b[A\n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=104.0]        \n",
      "Epoch 603: 100%|██████████| 1/1 [00:00<00:00, 75.36it/s, v_num=2587929, train_loss_step=0.0699, train_loss_epoch=0.0663, valid_loss=104.0]\n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=104.0]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=104.0]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=104.0]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=104.0]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0566, train_loss_epoch=0.0566, valid_loss=104.0]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=104.0]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0571, train_loss_epoch=0.0571, valid_loss=104.0]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0568, train_loss_epoch=0.0568, valid_loss=104.0]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=104.0]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=104.0]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.081, train_loss_epoch=0.081, valid_loss=104.0]          \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=104.0]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=104.0]        \n",
      "Epoch 677: 100%|██████████| 1/1 [00:00<00:00, 77.58it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=104.0]\n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=104.0]          \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0507, train_loss_epoch=0.0507, valid_loss=104.0]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=104.0]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 76.16it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.85it/s]\u001b[A\n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=79.10]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=79.10]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=79.10]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0601, train_loss_epoch=0.0601, valid_loss=79.10]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=79.10]        \n",
      "Epoch 728: 100%|██████████| 1/1 [00:00<00:00, 74.04it/s, v_num=2587929, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=79.10]\n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=79.10]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=79.10]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=79.10]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0526, train_loss_epoch=0.0526, valid_loss=79.10]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=79.10]          \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.060, train_loss_epoch=0.060, valid_loss=79.10]          \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=79.10]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=79.10]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=79.10]        \n",
      "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 76.67it/s, v_num=2587929, train_loss_step=0.0538, train_loss_epoch=0.0546, valid_loss=79.10]\n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=79.10]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.053, train_loss_epoch=0.053, valid_loss=79.10]          \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 76.22it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0497, valid_loss=79.10]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.92it/s]\u001b[A\n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=88.90]          \n",
      "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 73.53it/s, v_num=2587929, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=88.90]\n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=88.90]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=88.90]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=88.90]        \n",
      "Epoch 816: 100%|██████████| 1/1 [00:00<00:00, 72.27it/s, v_num=2587929, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=88.90]\n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=88.90]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=88.90]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0799, train_loss_epoch=0.0799, valid_loss=88.90]        \n",
      "Epoch 831: 100%|██████████| 1/1 [00:00<00:00, 77.59it/s, v_num=2587929, train_loss_step=0.0799, train_loss_epoch=0.0799, valid_loss=88.90]\n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0646, train_loss_epoch=0.0646, valid_loss=88.90]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0544, train_loss_epoch=0.0544, valid_loss=88.90]        \n",
      "Epoch 846: 100%|██████████| 1/1 [00:00<00:00, 74.72it/s, v_num=2587929, train_loss_step=0.0553, train_loss_epoch=0.0553, valid_loss=88.90]\n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0553, train_loss_epoch=0.0553, valid_loss=88.90]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=88.90]        \n",
      "Epoch 861: 100%|██████████| 1/1 [00:00<00:00, 75.61it/s, v_num=2587929, train_loss_step=0.0782, train_loss_epoch=0.0782, valid_loss=88.90]\n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0782, train_loss_epoch=0.0782, valid_loss=88.90]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=88.90]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=88.90]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=88.90]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=88.90]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=88.90]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0595, train_loss_epoch=0.0595, valid_loss=88.90]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0572, train_loss_epoch=0.0572, valid_loss=88.90]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 75.28it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0572, valid_loss=88.90]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.98it/s]\u001b[A\n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0587, train_loss_epoch=0.0587, valid_loss=104.0]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=104.0]        \n",
      "Epoch 912: 100%|██████████| 1/1 [00:00<00:00, 74.12it/s, v_num=2587929, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=104.0]  \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=104.0]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=104.0]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0556, train_loss_epoch=0.0556, valid_loss=104.0]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=104.0]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=104.0]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=104.0]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=104.0]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0941, train_loss_epoch=0.0941, valid_loss=104.0]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=104.0]        \n",
      "Epoch 963: 100%|██████████| 1/1 [00:00<00:00, 71.10it/s, v_num=2587929, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=104.0]\n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=104.0]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=104.0]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0861, train_loss_epoch=0.0861, valid_loss=104.0]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0572, train_loss_epoch=0.0572, valid_loss=104.0]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=104.0]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0542, train_loss_epoch=0.0542, valid_loss=104.0]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 71.59it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0556, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.63it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516035)\u001b[0m \n",
      "                                                                       \u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 34.81it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=85.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=516035)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m /home/hmf6av/.local/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m [rank: 0] Seed set to 1\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 0 | loss            | MAE           | 0      | train\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 4 | context_adapter | Linear        | 8.0 K  | train\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 494 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 494 K     Total params\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 1.978     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.560, train_loss_epoch=3.560]        \n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 70.80it/s, v_num=2587929, train_loss_step=3.530, train_loss_epoch=3.530]\n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.530, train_loss_epoch=3.530]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.280, train_loss_epoch=2.280]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.540, train_loss_epoch=1.540]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.500, train_loss_epoch=1.500]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.250, train_loss_epoch=1.250]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.952, train_loss_epoch=0.952]        \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 75.61it/s, v_num=2587929, train_loss_step=0.932, train_loss_epoch=0.952]\n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.932, train_loss_epoch=0.932]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.822, train_loss_epoch=0.822]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.700, train_loss_epoch=0.700]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.618, train_loss_epoch=0.618]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.527, train_loss_epoch=0.527]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.509, train_loss_epoch=0.509]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.513, train_loss_epoch=0.513]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 76.43it/s, v_num=2587929, train_loss_step=0.418, train_loss_epoch=0.450]\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.84it/s]\u001b[A\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 77.53it/s, v_num=2587929, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=677.0]\n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=677.0]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=677.0]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=677.0]        \n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 72.09it/s, v_num=2587929, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=677.0]\n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=677.0]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=677.0]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=677.0]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=677.0]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=677.0]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=677.0]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=677.0]        \n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 72.89it/s, v_num=2587929, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=677.0]\n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=677.0]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=677.0]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=677.0]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=677.0]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 76.73it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.174, valid_loss=677.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.71it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=159.0]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=159.0]        \n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 76.75it/s, v_num=2587929, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=159.0]\n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=159.0]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=159.0]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=159.0]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=159.0]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=159.0]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=159.0]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=159.0]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=159.0]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=159.0]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=159.0]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=159.0]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=159.0]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=159.0]        \n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 76.11it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.109, valid_loss=159.0]\n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=159.0]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 75.39it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.0989, valid_loss=159.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.14it/s]\u001b[A\n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]          \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0979, train_loss_epoch=0.0979, valid_loss=113.0]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=113.0]          \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=113.0]          \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=113.0]          \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0821, train_loss_epoch=0.0821, valid_loss=113.0]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=113.0]          \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=113.0]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0956, train_loss_epoch=0.0956, valid_loss=113.0]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0898, train_loss_epoch=0.0898, valid_loss=113.0]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0905, train_loss_epoch=0.0905, valid_loss=113.0]        \n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 74.97it/s, v_num=2587929, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=113.0]  \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=113.0]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=113.0]          \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=113.0]          \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=113.0]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 75.90it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.68it/s]\u001b[A\n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0868, train_loss_epoch=0.0868, valid_loss=112.0]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.093, train_loss_epoch=0.093, valid_loss=112.0]          \n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 74.35it/s, v_num=2587929, train_loss_step=0.0962, train_loss_epoch=0.093, valid_loss=112.0]\n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0962, train_loss_epoch=0.0962, valid_loss=112.0]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=112.0]          \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0801, train_loss_epoch=0.0801, valid_loss=112.0]        \n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 74.48it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=112.0]  \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=112.0]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=112.0]          \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=112.0]          \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=112.0]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.084, train_loss_epoch=0.084, valid_loss=112.0]          \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=112.0]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0962, train_loss_epoch=0.0962, valid_loss=112.0]        \n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 75.03it/s, v_num=2587929, train_loss_step=0.0866, train_loss_epoch=0.123, valid_loss=112.0] \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0866, train_loss_epoch=0.0866, valid_loss=112.0]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=112.0]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0782, train_loss_epoch=0.0782, valid_loss=112.0]        \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 76.31it/s, v_num=2587929, train_loss_step=0.0999, train_loss_epoch=0.110, valid_loss=112.0] \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0999, train_loss_epoch=0.0999, valid_loss=112.0]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 76.99it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.090, valid_loss=112.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.57it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m \n",
      "Epoch 506: 100%|██████████| 1/1 [00:00<00:00, 77.49it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=97.40]  \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0923, train_loss_epoch=0.0923, valid_loss=97.40]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=97.40]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0852, train_loss_epoch=0.0852, valid_loss=97.40]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0801, train_loss_epoch=0.0801, valid_loss=97.40]        \n",
      "Epoch 528: 100%|██████████| 1/1 [00:00<00:00, 73.91it/s, v_num=2587929, train_loss_step=0.0801, train_loss_epoch=0.0801, valid_loss=97.40]\n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0705, train_loss_epoch=0.0705, valid_loss=97.40]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=97.40]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0681, train_loss_epoch=0.0681, valid_loss=97.40]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=97.40]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=97.40]        \n",
      "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 73.09it/s, v_num=2587929, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=97.40]\n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=97.40]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=97.40]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=97.40]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=97.40]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0642, train_loss_epoch=0.0642, valid_loss=97.40]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=97.40]        \n",
      "Epoch 587: 100%|██████████| 1/1 [00:00<00:00, 75.01it/s, v_num=2587929, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=97.40]\n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.070, train_loss_epoch=0.070, valid_loss=97.40]          \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=97.40]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 76.86it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0661, valid_loss=97.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.26it/s]\u001b[A\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0808, train_loss_epoch=0.0808, valid_loss=104.0]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0772, train_loss_epoch=0.0772, valid_loss=104.0]        \n",
      "Epoch 608: 100%|██████████| 1/1 [00:00<00:00, 75.68it/s, v_num=2587929, train_loss_step=0.0772, train_loss_epoch=0.0772, valid_loss=104.0]\n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=104.0]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=104.0]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=104.0]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=104.0]        \n",
      "Epoch 630: 100%|██████████| 1/1 [00:00<00:00, 74.08it/s, v_num=2587929, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=104.0]\n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=104.0]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=104.0]\n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0721, train_loss_epoch=0.0721, valid_loss=104.0]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0528, train_loss_epoch=0.0528, valid_loss=104.0]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=104.0]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0571, train_loss_epoch=0.0571, valid_loss=104.0]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0745, train_loss_epoch=0.0745, valid_loss=104.0]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=104.0]          \n",
      "Epoch 667: 100%|██████████| 1/1 [00:00<00:00, 73.73it/s, v_num=2587929, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=104.0]\n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=104.0]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=104.0]          \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=104.0]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.045, train_loss_epoch=0.045, valid_loss=104.0]          \n",
      "Epoch 689: 100%|██████████| 1/1 [00:00<00:00, 73.32it/s, v_num=2587929, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=104.0]\n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=104.0]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=104.0]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 76.56it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.12it/s]\u001b[A\n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0707, train_loss_epoch=0.0707, valid_loss=79.10]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=79.10]          \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=79.10]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=79.10]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=79.10]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=79.10]        \n",
      "Epoch 732: 100%|██████████| 1/1 [00:00<00:00, 72.12it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=79.10]\n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=79.10]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0586, train_loss_epoch=0.0586, valid_loss=79.10]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0584, train_loss_epoch=0.0584, valid_loss=79.10]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0693, train_loss_epoch=0.0693, valid_loss=79.10]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=79.10]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=79.10]          \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=79.10]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0625, train_loss_epoch=0.0625, valid_loss=79.10]        \n",
      "Epoch 783: 100%|██████████| 1/1 [00:00<00:00, 75.68it/s, v_num=2587929, train_loss_step=0.055, train_loss_epoch=0.0541, valid_loss=79.10] \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=79.10]         \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=79.10]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=79.10]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 72.47it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0497, valid_loss=79.10]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.29it/s]\u001b[A\n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=88.90]          \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=88.90]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=88.90]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0586, train_loss_epoch=0.0586, valid_loss=88.90]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=88.90]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=88.90]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=88.90]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=88.90]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0554, train_loss_epoch=0.0554, valid_loss=88.90]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=88.90]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=88.90]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=88.90]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=88.90]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=88.90]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0449, train_loss_epoch=0.0449, valid_loss=88.90]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=88.90]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0615, train_loss_epoch=0.0615, valid_loss=88.90]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 74.46it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0572, valid_loss=88.90]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.65it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516149)\u001b[0m \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0613, train_loss_epoch=0.0613, valid_loss=104.0]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=104.0]          \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=104.0]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=104.0]        \n",
      "Epoch 921: 100%|██████████| 1/1 [00:00<00:00, 73.37it/s, v_num=2587929, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=104.0]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0485, train_loss_epoch=0.0485, valid_loss=104.0]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0512, valid_loss=104.0]        \n",
      "Epoch 936: 100%|██████████| 1/1 [00:00<00:00, 73.67it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0512, valid_loss=104.0]\n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=104.0]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=104.0]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=104.0]          \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0814, train_loss_epoch=0.0814, valid_loss=104.0]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=104.0]          \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=104.0]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0581, train_loss_epoch=0.0581, valid_loss=104.0]        \n",
      "Epoch 980: 100%|██████████| 1/1 [00:00<00:00, 76.23it/s, v_num=2587929, train_loss_step=0.0664, train_loss_epoch=0.069, valid_loss=104.0] \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=104.0]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=104.0]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=104.0]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=104.0]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 74.25it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0556, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.24it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 36.28it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=85.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=516149)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m /home/hmf6av/.local/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m [rank: 0] Seed set to 1\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 0 | loss            | MAE           | 0      | train\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 4 | context_adapter | Linear        | 8.0 K  | train\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 494 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 494 K     Total params\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 1.978     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.600, train_loss_epoch=3.600]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.340, train_loss_epoch=3.340]       \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.270, train_loss_epoch=3.270]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.520, train_loss_epoch=2.520]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.680, train_loss_epoch=1.680]        \n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 73.33it/s, v_num=2587929, train_loss_step=1.310, train_loss_epoch=1.310]\n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.310, train_loss_epoch=1.310]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 74.32it/s, v_num=2587929, train_loss_step=0.970, train_loss_epoch=0.970]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.970, train_loss_epoch=0.970]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.857, train_loss_epoch=0.857]        \n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 75.58it/s, v_num=2587929, train_loss_step=0.737, train_loss_epoch=0.737]\n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.721, train_loss_epoch=0.721]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.655, train_loss_epoch=0.655]        \n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 74.98it/s, v_num=2587929, train_loss_step=0.532, train_loss_epoch=0.532]\n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.509, train_loss_epoch=0.509]        \n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 73.72it/s, v_num=2587929, train_loss_step=0.451, train_loss_epoch=0.451]\n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.451, train_loss_epoch=0.451]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 77.03it/s, v_num=2587929, train_loss_step=0.418, train_loss_epoch=0.450]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.06it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=677.0]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=677.0]        \n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 76.05it/s, v_num=2587929, train_loss_step=0.348, train_loss_epoch=0.355, valid_loss=677.0]\n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=677.0]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=677.0]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=677.0]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=677.0]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=677.0]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=677.0]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=677.0]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=677.0]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=677.0]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=677.0]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=677.0]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=677.0]        \n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 73.79it/s, v_num=2587929, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=677.0]\n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=677.0]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=677.0]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 76.44it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.174, valid_loss=677.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.02it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=159.0]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=159.0]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=159.0]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=159.0]        \n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 74.11it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=159.0]\n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=159.0]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=159.0]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=159.0]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=159.0]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=159.0]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=159.0]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=159.0]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=159.0]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=159.0]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=159.0]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=159.0]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=159.0]        \n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 77.22it/s, v_num=2587929, train_loss_step=0.116, train_loss_epoch=0.148, valid_loss=159.0]\n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=159.0]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=159.0]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=159.0]        \n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 77.19it/s, v_num=2587929, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=159.0]\n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=159.0]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0989, train_loss_epoch=0.0989, valid_loss=159.0]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 74.73it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.0989, valid_loss=159.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.55it/s]\u001b[A\n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0984, train_loss_epoch=0.0984, valid_loss=113.0]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=113.0]          \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=113.0]          \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=113.0]        \n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 73.48it/s, v_num=2587929, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=113.0]  \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=113.0]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=113.0]          \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=113.0]          \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0893, train_loss_epoch=0.0893, valid_loss=113.0]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0857, train_loss_epoch=0.0857, valid_loss=113.0]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=113.0]          \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0977, train_loss_epoch=0.0977, valid_loss=113.0]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0966, train_loss_epoch=0.0966, valid_loss=113.0]        \n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 76.04it/s, v_num=2587929, train_loss_step=0.0966, train_loss_epoch=0.0966, valid_loss=113.0]\n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=113.0]          \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=113.0]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0855, train_loss_epoch=0.0855, valid_loss=113.0]        \n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 75.17it/s, v_num=2587929, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=113.0]  \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=113.0]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 76.16it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.73it/s]\u001b[A\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0944, train_loss_epoch=0.0944, valid_loss=112.0]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=112.0]          \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0833, train_loss_epoch=0.0833, valid_loss=112.0]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0845, train_loss_epoch=0.0845, valid_loss=112.0]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0899, train_loss_epoch=0.0899, valid_loss=112.0]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0905, train_loss_epoch=0.0905, valid_loss=112.0]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0775, train_loss_epoch=0.0775, valid_loss=112.0]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=112.0]          \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0902, train_loss_epoch=0.0902, valid_loss=112.0]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=112.0]          \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=112.0]          \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=112.0]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0974, train_loss_epoch=0.0974, valid_loss=112.0]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=112.0]          \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=112.0]          \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0851, train_loss_epoch=0.0851, valid_loss=112.0]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0715, train_loss_epoch=0.0715, valid_loss=112.0]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=112.0]          \n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 74.22it/s, v_num=2587929, train_loss_step=0.092, train_loss_epoch=0.092, valid_loss=112.0]\n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.092, train_loss_epoch=0.092, valid_loss=112.0]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.097, train_loss_epoch=0.097, valid_loss=112.0]          \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 76.56it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.090, valid_loss=112.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.69it/s]\u001b[A\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=97.40]          \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=97.40]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0936, train_loss_epoch=0.0936, valid_loss=97.40]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0894, train_loss_epoch=0.0894, valid_loss=97.40]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=97.40]        \n",
      "Epoch 533: 100%|██████████| 1/1 [00:00<00:00, 72.37it/s, v_num=2587929, train_loss_step=0.0752, train_loss_epoch=0.0752, valid_loss=97.40]\n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0752, train_loss_epoch=0.0752, valid_loss=97.40]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0592, train_loss_epoch=0.0592, valid_loss=97.40]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0581, train_loss_epoch=0.0581, valid_loss=97.40]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0605, train_loss_epoch=0.0605, valid_loss=97.40]        \n",
      "Epoch 555: 100%|██████████| 1/1 [00:00<00:00, 74.20it/s, v_num=2587929, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=97.40]\n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=97.40]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=97.40]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=97.40]          \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0597, train_loss_epoch=0.0597, valid_loss=97.40]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=97.40]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=97.40]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=97.40]        \n",
      "Epoch 592: 100%|██████████| 1/1 [00:00<00:00, 74.97it/s, v_num=2587929, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=97.40]\n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=97.40]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 75.99it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0661, valid_loss=97.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.31it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=104.0]          \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=104.0]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=104.0]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0544, train_loss_epoch=0.0544, valid_loss=104.0]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0642, train_loss_epoch=0.0642, valid_loss=104.0]        \n",
      "Epoch 635: 100%|██████████| 1/1 [00:00<00:00, 76.56it/s, v_num=2587929, train_loss_step=0.0599, train_loss_epoch=0.0675, valid_loss=104.0]\n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0599, train_loss_epoch=0.0599, valid_loss=104.0]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0554, train_loss_epoch=0.0554, valid_loss=104.0]        \n",
      "Epoch 650: 100%|██████████| 1/1 [00:00<00:00, 76.94it/s, v_num=2587929, train_loss_step=0.060, train_loss_epoch=0.060, valid_loss=104.0]  \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0568, train_loss_epoch=0.0568, valid_loss=104.0]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0536, train_loss_epoch=0.0536, valid_loss=104.0]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0752, train_loss_epoch=0.0752, valid_loss=104.0]        \n",
      "Epoch 672: 100%|██████████| 1/1 [00:00<00:00, 74.97it/s, v_num=2587929, train_loss_step=0.0576, train_loss_epoch=0.0508, valid_loss=104.0]\n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=104.0]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.056, train_loss_epoch=0.056, valid_loss=104.0]          \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=104.0]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=104.0]        \n",
      "Epoch 694: 100%|██████████| 1/1 [00:00<00:00, 75.51it/s, v_num=2587929, train_loss_step=0.0616, train_loss_epoch=0.0666, valid_loss=104.0]\n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=104.0]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 77.28it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.21it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=79.10]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=79.10]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=79.10]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=79.10]        \n",
      "Epoch 723: 100%|██████████| 1/1 [00:00<00:00, 73.48it/s, v_num=2587929, train_loss_step=0.0536, train_loss_epoch=0.0536, valid_loss=79.10]\n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0536, train_loss_epoch=0.0536, valid_loss=79.10]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=79.10]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0568, train_loss_epoch=0.0568, valid_loss=79.10]        \n",
      "Epoch 745: 100%|██████████| 1/1 [00:00<00:00, 76.19it/s, v_num=2587929, train_loss_step=0.0592, train_loss_epoch=0.0617, valid_loss=79.10]\n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0592, train_loss_epoch=0.0592, valid_loss=79.10]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=79.10]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0597, train_loss_epoch=0.0597, valid_loss=79.10]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=79.10]          \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0602, train_loss_epoch=0.0602, valid_loss=79.10]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=79.10]        \n",
      "Epoch 782: 100%|██████████| 1/1 [00:00<00:00, 75.31it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0498, valid_loss=79.10]\n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=79.10]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=79.10]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.051, train_loss_epoch=0.051, valid_loss=79.10]          \n",
      "Epoch 797: 100%|██████████| 1/1 [00:00<00:00, 72.68it/s, v_num=2587929, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=79.10]\n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=79.10]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 75.28it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0497, valid_loss=79.10]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.89it/s]\u001b[A\n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=88.90]          \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=88.90]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=88.90]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0586, train_loss_epoch=0.0586, valid_loss=88.90]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=88.90]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=88.90]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=88.90]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=88.90]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0554, train_loss_epoch=0.0554, valid_loss=88.90]        \n",
      "Epoch 848: 100%|██████████| 1/1 [00:00<00:00, 76.39it/s, v_num=2587929, train_loss_step=0.0516, train_loss_epoch=0.0554, valid_loss=88.90]\n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=88.90]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=88.90]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=88.90]        \n",
      "Epoch 863: 100%|██████████| 1/1 [00:00<00:00, 75.75it/s, v_num=2587929, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=88.90]\n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=88.90]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=88.90]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=88.90]        \n",
      "Epoch 885: 100%|██████████| 1/1 [00:00<00:00, 72.21it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=88.90]\n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=88.90]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0615, train_loss_epoch=0.0615, valid_loss=88.90]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 75.54it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0572, valid_loss=88.90]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.17it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516253)\u001b[0m \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=104.0]        \n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=104.0]\n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=104.0]          \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=104.0]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.056, train_loss_epoch=0.056, valid_loss=104.0]          \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=104.0]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0485, train_loss_epoch=0.0485, valid_loss=104.0]        \n",
      "Epoch 936: 100%|██████████| 1/1 [00:00<00:00, 74.95it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0512, valid_loss=104.0]\n",
      "Epoch 936: 100%|██████████| 1/1 [00:00<00:00, 73.06it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=104.0]\n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=104.0]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=104.0]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=104.0]          \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=104.0]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=104.0]          \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=104.0]        \n",
      "Epoch 973: 100%|██████████| 1/1 [00:00<00:00, 77.08it/s, v_num=2587929, train_loss_step=0.0882, train_loss_epoch=0.0581, valid_loss=104.0]\n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=104.0]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=104.0]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=104.0]        \n",
      "Epoch 988: 100%|██████████| 1/1 [00:00<00:00, 74.37it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=104.0]\n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=104.0]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=104.0]        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=516253)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 76.67it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0556, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.63it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 37.75it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=85.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=516380)\u001b[0m /home/hmf6av/.local/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m [rank: 0] Seed set to 1\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 0 | loss            | MAE           | 0      | train\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 4 | context_adapter | Linear        | 8.0 K  | train\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 494 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 494 K     Total params\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 1.978     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=516380)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.500, train_loss_epoch=3.500]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.020, train_loss_epoch=3.020]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.920, train_loss_epoch=2.920]\n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.050, train_loss_epoch=2.050]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.480, train_loss_epoch=1.480]        \n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 75.37it/s, v_num=2587929, train_loss_step=1.440, train_loss_epoch=1.440]\n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.440, train_loss_epoch=1.440]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.210, train_loss_epoch=1.210]        \n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 73.79it/s, v_num=2587929, train_loss_step=1.010, train_loss_epoch=1.010]\n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.899, train_loss_epoch=0.899]        \n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 73.81it/s, v_num=2587929, train_loss_step=0.777, train_loss_epoch=0.789]\n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.777, train_loss_epoch=0.777]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.643, train_loss_epoch=0.643]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.596, train_loss_epoch=0.596]        \n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 73.70it/s, v_num=2587929, train_loss_step=0.564, train_loss_epoch=0.564]\n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.564, train_loss_epoch=0.564]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.495, train_loss_epoch=0.495]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.524, train_loss_epoch=0.524]        \n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 73.16it/s, v_num=2587929, train_loss_step=0.466, train_loss_epoch=0.466]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.466, train_loss_epoch=0.466]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.464, train_loss_epoch=0.464]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 75.53it/s, v_num=2587929, train_loss_step=0.418, train_loss_epoch=0.450]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.37it/s]\u001b[A\n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=677.0]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=677.0]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=677.0]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=677.0]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=677.0]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=677.0]        \n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 72.73it/s, v_num=2587929, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=677.0]\n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=677.0]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=677.0]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=677.0]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=677.0]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=677.0]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=677.0]        \n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 70.95it/s, v_num=2587929, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=677.0]\n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=677.0]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=677.0]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=677.0]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=677.0]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=677.0]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=677.0]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 77.25it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.174, valid_loss=677.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.81it/s]\u001b[A\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 72.44it/s, v_num=2587929, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=159.0]\n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=159.0]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=159.0]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=159.0]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=159.0]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=159.0]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=159.0]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=159.0]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=159.0]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=159.0]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=159.0]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=159.0]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=159.0]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=159.0]        \n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 73.92it/s, v_num=2587929, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=159.0]\n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=159.0]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=159.0]        \n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 76.42it/s, v_num=2587929, train_loss_step=0.121, train_loss_epoch=0.116, valid_loss=159.0]\n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=159.0]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=159.0]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 76.88it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.0989, valid_loss=159.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.77it/s]\u001b[A\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 76.47it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.0994, valid_loss=113.0] \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]         \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0979, train_loss_epoch=0.0979, valid_loss=113.0]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=113.0]          \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=113.0]          \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0847, train_loss_epoch=0.0847, valid_loss=113.0]        \n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 73.28it/s, v_num=2587929, train_loss_step=0.0821, train_loss_epoch=0.0821, valid_loss=113.0]\n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0821, train_loss_epoch=0.0821, valid_loss=113.0]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=113.0]          \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=113.0]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=113.0]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0956, train_loss_epoch=0.0956, valid_loss=113.0]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0898, train_loss_epoch=0.0898, valid_loss=113.0]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0895, train_loss_epoch=0.0895, valid_loss=113.0]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0895, train_loss_epoch=0.0895, valid_loss=113.0]\n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=113.0]          \n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 74.54it/s, v_num=2587929, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=113.0]  \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=113.0]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]          \n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 74.26it/s, v_num=2587929, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=113.0]  \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=113.0]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 72.57it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.19it/s]\u001b[A\n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=112.0]          \n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 76.38it/s, v_num=2587929, train_loss_step=0.0934, train_loss_epoch=0.0962, valid_loss=112.0]\n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0934, train_loss_epoch=0.0934, valid_loss=112.0]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0935, train_loss_epoch=0.0935, valid_loss=112.0]        \n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 76.21it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=112.0]  \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0922, train_loss_epoch=0.0922, valid_loss=112.0]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=112.0]          \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=112.0]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0911, train_loss_epoch=0.0911, valid_loss=112.0]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=112.0]          \n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 75.06it/s, v_num=2587929, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=112.0]\n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=112.0]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=112.0]          \n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 74.07it/s, v_num=2587929, train_loss_step=0.123, train_loss_epoch=0.136, valid_loss=112.0]  \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=112.0]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=112.0]          \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0854, train_loss_epoch=0.0854, valid_loss=112.0]        \n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 72.64it/s, v_num=2587929, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=112.0]  \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=112.0]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0895, train_loss_epoch=0.0895, valid_loss=112.0]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 76.66it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.090, valid_loss=112.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.67it/s]\u001b[A\n",
      "Epoch 501: 100%|██████████| 1/1 [00:00<00:00, 74.99it/s, v_num=2587929, train_loss_step=0.0996, train_loss_epoch=0.0863, valid_loss=97.40]\n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0996, train_loss_epoch=0.0996, valid_loss=97.40]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0918, train_loss_epoch=0.0918, valid_loss=97.40]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=97.40]          \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0837, train_loss_epoch=0.0837, valid_loss=97.40]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=97.40]          \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=97.40]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0626, train_loss_epoch=0.0626, valid_loss=97.40]        \n",
      "Epoch 546: 100%|██████████| 1/1 [00:00<00:00, 74.17it/s, v_num=2587929, train_loss_step=0.0581, train_loss_epoch=0.0581, valid_loss=97.40]\n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0581, train_loss_epoch=0.0581, valid_loss=97.40]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0675, train_loss_epoch=0.0675, valid_loss=97.40]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=97.40]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=97.40]        \n",
      "Epoch 568: 100%|██████████| 1/1 [00:00<00:00, 73.63it/s, v_num=2587929, train_loss_step=0.0568, train_loss_epoch=0.0568, valid_loss=97.40]\n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0568, train_loss_epoch=0.0568, valid_loss=97.40]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=97.40]          \n",
      "Epoch 583: 100%|██████████| 1/1 [00:00<00:00, 74.17it/s, v_num=2587929, train_loss_step=0.0686, train_loss_epoch=0.0686, valid_loss=97.40]\n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0686, train_loss_epoch=0.0686, valid_loss=97.40]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0768, train_loss_epoch=0.0768, valid_loss=97.40]        \n",
      "Epoch 598: 100%|██████████| 1/1 [00:00<00:00, 76.77it/s, v_num=2587929, train_loss_step=0.0661, train_loss_epoch=0.0799, valid_loss=97.40]\n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=97.40]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 71.08it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0661, valid_loss=97.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.96it/s]\u001b[A\n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0689, train_loss_epoch=0.0689, valid_loss=104.0]        \n",
      "Epoch 612: 100%|██████████| 1/1 [00:00<00:00, 74.53it/s, v_num=2587929, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=104.0]\n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=104.0]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0562, train_loss_epoch=0.0562, valid_loss=104.0]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0687, train_loss_epoch=0.0687, valid_loss=104.0]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=104.0]          \n",
      "Epoch 641: 100%|██████████| 1/1 [00:00<00:00, 74.27it/s, v_num=2587929, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=104.0]\n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=104.0]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0713, train_loss_epoch=0.0713, valid_loss=104.0]        \n",
      "Epoch 656: 100%|██████████| 1/1 [00:00<00:00, 75.85it/s, v_num=2587929, train_loss_step=0.0825, train_loss_epoch=0.0825, valid_loss=104.0]\n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0825, train_loss_epoch=0.0825, valid_loss=104.0]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=104.0]        \n",
      "Epoch 671: 100%|██████████| 1/1 [00:00<00:00, 73.97it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=104.0]\n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=104.0]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0584, train_loss_epoch=0.0584, valid_loss=104.0]        \n",
      "Epoch 686: 100%|██████████| 1/1 [00:00<00:00, 76.96it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0573, valid_loss=104.0]\n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=104.0]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=104.0]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 75.91it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.49it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=79.10]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0585, train_loss_epoch=0.0585, valid_loss=79.10]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=79.10]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=79.10]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=79.10]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=79.10]        \n",
      "Epoch 737: 100%|██████████| 1/1 [00:00<00:00, 73.66it/s, v_num=2587929, train_loss_step=0.0568, train_loss_epoch=0.0568, valid_loss=79.10]\n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0568, train_loss_epoch=0.0568, valid_loss=79.10]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=79.10]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=79.10]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=79.10]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0597, train_loss_epoch=0.0597, valid_loss=79.10]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=79.10]          \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=79.10]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0602, train_loss_epoch=0.0602, valid_loss=79.10]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=79.10]        \n",
      "Epoch 782: 100%|██████████| 1/1 [00:00<00:00, 73.07it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=79.10]\n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=79.10]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=79.10]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.051, train_loss_epoch=0.051, valid_loss=79.10]          \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 76.46it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0497, valid_loss=79.10]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.54it/s]\u001b[A\n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=88.90]          \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=88.90]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=88.90]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0586, train_loss_epoch=0.0586, valid_loss=88.90]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=88.90]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=88.90]        \n",
      "Epoch 840: 100%|██████████| 1/1 [00:00<00:00, 73.28it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=88.90]\n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=88.90]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0554, train_loss_epoch=0.0554, valid_loss=88.90]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=88.90]        \n",
      "Epoch 855: 100%|██████████| 1/1 [00:00<00:00, 74.59it/s, v_num=2587929, train_loss_step=0.0498, train_loss_epoch=0.0617, valid_loss=88.90]\n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=88.90]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=88.90]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0632, train_loss_epoch=0.0632, valid_loss=88.90]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=88.90]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=88.90]\n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=88.90]        \n",
      "Epoch 885: 100%|██████████| 1/1 [00:00<00:00, 73.13it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=88.90]\n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=88.90]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0615, train_loss_epoch=0.0615, valid_loss=88.90]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 77.10it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0572, valid_loss=88.90]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.33it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=104.0]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=104.0]          \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=104.0]        \n",
      "Epoch 914: 100%|██████████| 1/1 [00:00<00:00, 72.41it/s, v_num=2587929, train_loss_step=0.056, train_loss_epoch=0.056, valid_loss=104.0]  \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.056, train_loss_epoch=0.056, valid_loss=104.0]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=104.0]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0485, train_loss_epoch=0.0485, valid_loss=104.0]        \n",
      "Epoch 929: 100%|██████████| 1/1 [00:00<00:00, 74.45it/s, v_num=2587929, train_loss_step=0.0451, train_loss_epoch=0.0451, valid_loss=104.0]\n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0451, train_loss_epoch=0.0451, valid_loss=104.0]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=104.0]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=104.0]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=104.0]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=104.0]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=104.0]          \n",
      "Epoch 959: 100%|██████████| 1/1 [00:00<00:00, 75.39it/s, v_num=2587929, train_loss_step=0.0886, train_loss_epoch=0.075, valid_loss=104.0]\n",
      "Epoch 959: 100%|██████████| 1/1 [00:00<00:00, 73.47it/s, v_num=2587929, train_loss_step=0.0886, train_loss_epoch=0.0886, valid_loss=104.0]\n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0886, train_loss_epoch=0.0886, valid_loss=104.0]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0772, train_loss_epoch=0.0772, valid_loss=104.0]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=104.0]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=104.0]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=104.0]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=104.0]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0431, train_loss_epoch=0.0431, valid_loss=104.0]        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=516380)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 77.22it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0556, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.96it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 36.78it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=85.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=516489)\u001b[0m /home/hmf6av/.local/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m [rank: 0] Seed set to 1\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 0 | loss            | MAE           | 0      | train\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 4 | context_adapter | Linear        | 8.0 K  | train\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 494 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 494 K     Total params\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 1.978     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 70.85it/s, v_num=2587929, train_loss_step=3.600, train_loss_epoch=3.600]\n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.600, train_loss_epoch=3.600]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.340, train_loss_epoch=3.340]       \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.670, train_loss_epoch=2.670]        \n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 74.35it/s, v_num=2587929, train_loss_step=2.520, train_loss_epoch=2.520]\n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.520, train_loss_epoch=2.520]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.680, train_loss_epoch=1.680]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.340, train_loss_epoch=1.340]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.310, train_loss_epoch=1.310]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.984, train_loss_epoch=0.984]        \n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 75.21it/s, v_num=2587929, train_loss_step=0.970, train_loss_epoch=0.970]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.970, train_loss_epoch=0.970]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.857, train_loss_epoch=0.857]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.737, train_loss_epoch=0.737]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.721, train_loss_epoch=0.721]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.655, train_loss_epoch=0.655]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.509, train_loss_epoch=0.509]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.513, train_loss_epoch=0.513]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.451, train_loss_epoch=0.451]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 76.49it/s, v_num=2587929, train_loss_step=0.418, train_loss_epoch=0.450]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.85it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=677.0]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=677.0]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=677.0]        \n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 76.02it/s, v_num=2587929, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=677.0]\n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=677.0]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=677.0]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=677.0]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=677.0]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=677.0]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=677.0]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=677.0]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=677.0]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=677.0]        \n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 76.26it/s, v_num=2587929, train_loss_step=0.203, train_loss_epoch=0.192, valid_loss=677.0]\n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=677.0]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=677.0]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=677.0]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=677.0]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=677.0]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 76.48it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.174, valid_loss=677.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.61it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=159.0]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=159.0]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=159.0]        \n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 73.48it/s, v_num=2587929, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=159.0]\n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=159.0]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=159.0]        \n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 73.11it/s, v_num=2587929, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=159.0]\n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=159.0]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=159.0]        \n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 75.11it/s, v_num=2587929, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=159.0]\n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=159.0]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=159.0]        \n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 74.04it/s, v_num=2587929, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=159.0]\n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=159.0]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=159.0]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=159.0]        \n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 73.00it/s, v_num=2587929, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=159.0]\n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=159.0]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=159.0]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=159.0]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=159.0]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=159.0]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0989, train_loss_epoch=0.0989, valid_loss=159.0]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 74.76it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.0989, valid_loss=159.0] \n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516489)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.90it/s]\u001b[A\n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=113.0]          \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=113.0]          \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=113.0]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=113.0]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=113.0]          \n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 75.27it/s, v_num=2587929, train_loss_step=0.0978, train_loss_epoch=0.118, valid_loss=113.0]\n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0978, train_loss_epoch=0.0978, valid_loss=113.0]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.099, train_loss_epoch=0.099, valid_loss=113.0]          \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]          \n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 76.05it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]\n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=113.0]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=113.0]          \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0897, train_loss_epoch=0.0897, valid_loss=113.0]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0923, train_loss_epoch=0.0923, valid_loss=113.0]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=113.0]          \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=113.0]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=113.0]        \n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 77.45it/s, v_num=2587929, train_loss_step=0.0897, train_loss_epoch=0.100, valid_loss=113.0] \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0897, train_loss_epoch=0.0897, valid_loss=113.0]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=113.0]          \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 75.14it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.41it/s]\u001b[A\n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0881, train_loss_epoch=0.0881, valid_loss=112.0]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=112.0]          \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=112.0]          \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0987, train_loss_epoch=0.0987, valid_loss=112.0]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=112.0]          \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=112.0]          \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0849, train_loss_epoch=0.0849, valid_loss=112.0]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0826, train_loss_epoch=0.0826, valid_loss=112.0]        \n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 76.58it/s, v_num=2587929, train_loss_step=0.142, train_loss_epoch=0.141, valid_loss=112.0]  \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=112.0]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=112.0]          \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=112.0]          \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0966, train_loss_epoch=0.0966, valid_loss=112.0]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=112.0]          \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=112.0]          \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.090, train_loss_epoch=0.090, valid_loss=112.0]          \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 75.58it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.090, valid_loss=112.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.96it/s]\u001b[A\n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=97.40]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=97.40]          \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0969, train_loss_epoch=0.0969, valid_loss=97.40]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0845, train_loss_epoch=0.0845, valid_loss=97.40]        \n",
      "Epoch 520: 100%|██████████| 1/1 [00:00<00:00, 74.40it/s, v_num=2587929, train_loss_step=0.0852, train_loss_epoch=0.0852, valid_loss=97.40]\n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0852, train_loss_epoch=0.0852, valid_loss=97.40]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0801, train_loss_epoch=0.0801, valid_loss=97.40]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=97.40]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0681, train_loss_epoch=0.0681, valid_loss=97.40]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=97.40]        \n",
      "Epoch 550: 100%|██████████| 1/1 [00:00<00:00, 72.71it/s, v_num=2587929, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=97.40]  \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=97.40]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=97.40]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=97.40]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=97.40]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0642, train_loss_epoch=0.0642, valid_loss=97.40]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.070, train_loss_epoch=0.070, valid_loss=97.40]          \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=97.40]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 77.02it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0661, valid_loss=97.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.87it/s]\u001b[A\n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=104.0]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=104.0]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=104.0]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0715, train_loss_epoch=0.0715, valid_loss=104.0]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=104.0]          \n",
      "Epoch 631: 100%|██████████| 1/1 [00:00<00:00, 75.10it/s, v_num=2587929, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=104.0]\n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=104.0]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0535, train_loss_epoch=0.0535, valid_loss=104.0]        \n",
      "Epoch 646: 100%|██████████| 1/1 [00:00<00:00, 75.05it/s, v_num=2587929, train_loss_step=0.0689, train_loss_epoch=0.0573, valid_loss=104.0]\n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0689, train_loss_epoch=0.0689, valid_loss=104.0]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0603, train_loss_epoch=0.0603, valid_loss=104.0]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0833, train_loss_epoch=0.0833, valid_loss=104.0]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=104.0]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0596, train_loss_epoch=0.0596, valid_loss=104.0]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0531, train_loss_epoch=0.0531, valid_loss=104.0]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=104.0]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=104.0]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=104.0]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=104.0]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=104.0]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 75.64it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.99it/s]\u001b[A\n",
      "Epoch 705: 100%|██████████| 1/1 [00:00<00:00, 74.48it/s, v_num=2587929, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=79.10]\n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=79.10]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=79.10]        \n",
      "Epoch 720: 100%|██████████| 1/1 [00:00<00:00, 74.94it/s, v_num=2587929, train_loss_step=0.0601, train_loss_epoch=0.0601, valid_loss=79.10]\n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0601, train_loss_epoch=0.0601, valid_loss=79.10]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=79.10]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0493, train_loss_epoch=0.0493, valid_loss=79.10]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=79.10]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=79.10]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0526, train_loss_epoch=0.0526, valid_loss=79.10]        \n",
      "Epoch 750: 100%|██████████| 1/1 [00:00<00:00, 73.55it/s, v_num=2587929, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=79.10]  \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=79.10]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.060, train_loss_epoch=0.060, valid_loss=79.10]          \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=79.10]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=79.10]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=79.10]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=79.10]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.053, train_loss_epoch=0.053, valid_loss=79.10]          \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 75.50it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0497, valid_loss=79.10]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.91it/s]\u001b[A\n",
      "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 75.26it/s, v_num=2587929, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=88.90]\n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=88.90]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=88.90]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=88.90]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=88.90]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0799, train_loss_epoch=0.0799, valid_loss=88.90]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0646, train_loss_epoch=0.0646, valid_loss=88.90]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0544, train_loss_epoch=0.0544, valid_loss=88.90]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0592, train_loss_epoch=0.0592, valid_loss=88.90]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0553, train_loss_epoch=0.0553, valid_loss=88.90]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=88.90]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=88.90]          \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=88.90]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=88.90]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=88.90]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=88.90]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=88.90]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0595, train_loss_epoch=0.0595, valid_loss=88.90]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 76.09it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0572, valid_loss=88.90]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.38it/s]\u001b[A\n",
      "Epoch 904: 100%|██████████| 1/1 [00:00<00:00, 73.91it/s, v_num=2587929, train_loss_step=0.0587, train_loss_epoch=0.0587, valid_loss=104.0]\n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0587, train_loss_epoch=0.0587, valid_loss=104.0]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=104.0]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0507, train_loss_epoch=0.0507, valid_loss=104.0]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=104.0]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0556, train_loss_epoch=0.0556, valid_loss=104.0]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=104.0]          \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=104.0]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0609, train_loss_epoch=0.0609, valid_loss=104.0]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0941, train_loss_epoch=0.0941, valid_loss=104.0]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=104.0]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0791, train_loss_epoch=0.0791, valid_loss=104.0]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0741, train_loss_epoch=0.0741, valid_loss=104.0]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0745, train_loss_epoch=0.0745, valid_loss=104.0]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0556, train_loss_epoch=0.0556, valid_loss=104.0]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=104.0]          \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 71.88it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0556, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.75it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 34.27it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=85.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=516489)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m /home/hmf6av/.local/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m [rank: 0] Seed set to 1\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 0 | loss            | MAE           | 0      | train\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 4 | context_adapter | Linear        | 8.0 K  | train\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 494 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 494 K     Total params\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 1.978     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.560, train_loss_epoch=3.560]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.530, train_loss_epoch=3.530]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.280, train_loss_epoch=2.280]        \n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 75.26it/s, v_num=2587929, train_loss_step=2.150, train_loss_epoch=2.280]\n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=2.150, train_loss_epoch=2.150]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.500, train_loss_epoch=1.500]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.250, train_loss_epoch=1.250]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.932, train_loss_epoch=0.932]        \n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 75.21it/s, v_num=2587929, train_loss_step=0.915, train_loss_epoch=0.915]\n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.915, train_loss_epoch=0.915]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.801, train_loss_epoch=0.801]        \n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 73.93it/s, v_num=2587929, train_loss_step=0.710, train_loss_epoch=0.710]\n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.710, train_loss_epoch=0.710]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.582, train_loss_epoch=0.582]        \n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 75.13it/s, v_num=2587929, train_loss_step=0.504, train_loss_epoch=0.504]\n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.504, train_loss_epoch=0.504]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.516, train_loss_epoch=0.516]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.484, train_loss_epoch=0.484]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.484, train_loss_epoch=0.484]\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 73.89it/s, v_num=2587929, train_loss_step=0.418, train_loss_epoch=0.450]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.99it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=677.0]        \n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 73.84it/s, v_num=2587929, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=677.0]\n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=677.0]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=677.0]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=677.0]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=677.0]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=677.0]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=677.0]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=677.0]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=677.0]        \n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 76.23it/s, v_num=2587929, train_loss_step=0.284, train_loss_epoch=0.242, valid_loss=677.0]\n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=677.0]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=677.0]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=677.0]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=677.0]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=677.0]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=677.0]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=677.0]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=677.0]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 75.69it/s, v_num=2587929, train_loss_step=0.162, train_loss_epoch=0.174, valid_loss=677.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.93it/s]\u001b[A\n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=159.0]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=159.0]        \n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 74.34it/s, v_num=2587929, train_loss_step=0.167, train_loss_epoch=0.151, valid_loss=159.0]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=159.0]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=159.0]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=159.0]        \n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 72.26it/s, v_num=2587929, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=159.0]\n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=159.0]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=159.0]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=159.0]        \n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 75.82it/s, v_num=2587929, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=159.0]\n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=159.0]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=159.0]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=159.0]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=159.0]        \n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 63.60it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=159.0]\n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=159.0]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=159.0]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0989, train_loss_epoch=0.0989, valid_loss=159.0]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 67.83it/s, v_num=2587929, train_loss_step=0.113, train_loss_epoch=0.0989, valid_loss=159.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.56it/s]\u001b[A\n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0984, train_loss_epoch=0.0984, valid_loss=113.0]        \n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 67.77it/s, v_num=2587929, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=113.0]  \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=113.0]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=113.0]          \n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 67.17it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=113.0]\n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=113.0]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]          \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0821, train_loss_epoch=0.0821, valid_loss=113.0]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=113.0]          \n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 74.36it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=113.0]\n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=113.0]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=113.0]          \n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 76.47it/s, v_num=2587929, train_loss_step=0.0898, train_loss_epoch=0.0971, valid_loss=113.0]\n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0898, train_loss_epoch=0.0898, valid_loss=113.0]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0905, train_loss_epoch=0.0905, valid_loss=113.0]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=113.0]          \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=113.0]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=113.0]          \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=113.0]          \n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 72.97it/s, v_num=2587929, train_loss_step=0.099, train_loss_epoch=0.099, valid_loss=113.0]\n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.099, train_loss_epoch=0.099, valid_loss=113.0]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=113.0]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 75.65it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=113.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.97it/s]\u001b[A\n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0868, train_loss_epoch=0.0868, valid_loss=112.0]        \n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 72.39it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=112.0]  \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=112.0]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0962, train_loss_epoch=0.0962, valid_loss=112.0]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=112.0]          \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0935, train_loss_epoch=0.0935, valid_loss=112.0]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=112.0]          \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=112.0]          \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=112.0]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=112.0]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.084, train_loss_epoch=0.084, valid_loss=112.0]          \n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 77.21it/s, v_num=2587929, train_loss_step=0.084, train_loss_epoch=0.084, valid_loss=112.0]\n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=112.0]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=112.0]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=112.0]          \n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 73.66it/s, v_num=2587929, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=112.0]\n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=112.0]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=112.0]          \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=112.0]        \n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 73.86it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=112.0]  \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=112.0]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0854, train_loss_epoch=0.0854, valid_loss=112.0]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0895, train_loss_epoch=0.0895, valid_loss=112.0]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 77.67it/s, v_num=2587929, train_loss_step=0.0961, train_loss_epoch=0.090, valid_loss=112.0] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.11it/s]\u001b[A\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0863, train_loss_epoch=0.0863, valid_loss=97.40]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0918, train_loss_epoch=0.0918, valid_loss=97.40]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0918, train_loss_epoch=0.0918, valid_loss=97.40]\n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=97.40]          \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0846, train_loss_epoch=0.0846, valid_loss=97.40]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0773, train_loss_epoch=0.0773, valid_loss=97.40]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0659, train_loss_epoch=0.0659, valid_loss=97.40]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0588, train_loss_epoch=0.0588, valid_loss=97.40]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=97.40]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=97.40]          \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=97.40]        \n",
      "Epoch 567: 100%|██████████| 1/1 [00:00<00:00, 77.34it/s, v_num=2587929, train_loss_step=0.0593, train_loss_epoch=0.0593, valid_loss=97.40]\n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=97.40]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=97.40]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0717, train_loss_epoch=0.0717, valid_loss=97.40]        \n",
      "Epoch 582: 100%|██████████| 1/1 [00:00<00:00, 72.42it/s, v_num=2587929, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=97.40]\n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=97.40]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=97.40]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0603, train_loss_epoch=0.0603, valid_loss=97.40]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 77.51it/s, v_num=2587929, train_loss_step=0.0761, train_loss_epoch=0.0661, valid_loss=97.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.56it/s]\u001b[A\n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=104.0]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=104.0]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=104.0]        \n",
      "Epoch 618: 100%|██████████| 1/1 [00:00<00:00, 73.57it/s, v_num=2587929, train_loss_step=0.0589, train_loss_epoch=0.0589, valid_loss=104.0]\n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0589, train_loss_epoch=0.0589, valid_loss=104.0]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0566, train_loss_epoch=0.0566, valid_loss=104.0]        \n",
      "Epoch 633: 100%|██████████| 1/1 [00:00<00:00, 75.22it/s, v_num=2587929, train_loss_step=0.052, train_loss_epoch=0.0674, valid_loss=104.0] \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=104.0]         \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0714, train_loss_epoch=0.0714, valid_loss=104.0]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0568, train_loss_epoch=0.0568, valid_loss=104.0]        \n",
      "Epoch 655: 100%|██████████| 1/1 [00:00<00:00, 75.32it/s, v_num=2587929, train_loss_step=0.0593, train_loss_epoch=0.0593, valid_loss=104.0]\n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0593, train_loss_epoch=0.0593, valid_loss=104.0]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.081, train_loss_epoch=0.081, valid_loss=104.0]          \n",
      "Epoch 670: 100%|██████████| 1/1 [00:00<00:00, 72.38it/s, v_num=2587929, train_loss_step=0.0562, train_loss_epoch=0.0562, valid_loss=104.0]\n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0562, train_loss_epoch=0.0562, valid_loss=104.0]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=104.0]          \n",
      "Epoch 685: 100%|██████████| 1/1 [00:00<00:00, 73.68it/s, v_num=2587929, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=104.0]\n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=104.0]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0535, train_loss_epoch=0.0535, valid_loss=104.0]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 76.03it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.26it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m \n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0549, train_loss_epoch=0.0549, valid_loss=79.10]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.063, train_loss_epoch=0.063, valid_loss=79.10]          \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=79.10]        \n",
      "Epoch 714: 100%|██████████| 1/1 [00:00<00:00, 74.80it/s, v_num=2587929, train_loss_step=0.0576, train_loss_epoch=0.0619, valid_loss=79.10]\n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=79.10]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=79.10]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=79.10]        \n",
      "Epoch 729: 100%|██████████| 1/1 [00:00<00:00, 73.99it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=79.10]\n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=79.10]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=79.10]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=79.10]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=79.10]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=79.10]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=79.10]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=79.10]          \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=79.10]        \n",
      "Epoch 781: 100%|██████████| 1/1 [00:00<00:00, 76.44it/s, v_num=2587929, train_loss_step=0.0498, train_loss_epoch=0.0588, valid_loss=79.10]\n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=79.10]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=79.10]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=79.10]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.051, train_loss_epoch=0.051, valid_loss=79.10]          \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 75.76it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0497, valid_loss=79.10]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.31it/s]\u001b[A\n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=88.90]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0438, train_loss_epoch=0.0438, valid_loss=88.90]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=88.90]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=88.90]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.069, train_loss_epoch=0.069, valid_loss=88.90]          \n",
      "Epoch 825: 100%|██████████| 1/1 [00:00<00:00, 73.29it/s, v_num=2587929, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=88.90]\n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=88.90]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=88.90]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0582, train_loss_epoch=0.0582, valid_loss=88.90]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0554, train_loss_epoch=0.0554, valid_loss=88.90]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=88.90]        \n",
      "Epoch 855: 100%|██████████| 1/1 [00:00<00:00, 74.91it/s, v_num=2587929, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=88.90]\n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=88.90]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=88.90]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0632, train_loss_epoch=0.0632, valid_loss=88.90]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=88.90]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=88.90]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0449, train_loss_epoch=0.0449, valid_loss=88.90]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0615, train_loss_epoch=0.0615, valid_loss=88.90]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 76.30it/s, v_num=2587929, train_loss_step=0.0453, train_loss_epoch=0.0572, valid_loss=88.90]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.68it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m \n",
      "Epoch 906: 100%|██████████| 1/1 [00:00<00:00, 75.32it/s, v_num=2587929, train_loss_step=0.054, train_loss_epoch=0.0613, valid_loss=104.0] \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=104.0]         \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=104.0]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=104.0]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=104.0]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=104.0]\n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0485, train_loss_epoch=0.0485, valid_loss=104.0]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0512, train_loss_epoch=0.0512, valid_loss=104.0]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0524, train_loss_epoch=0.0524, valid_loss=104.0]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=104.0]          \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0814, train_loss_epoch=0.0814, valid_loss=104.0]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=104.0]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=104.0]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0581, train_loss_epoch=0.0581, valid_loss=104.0]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.069, train_loss_epoch=0.069, valid_loss=104.0]          \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=104.0]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=104.0]        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 18:20:26,174\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/hmf6av/ray_results/_train_tune_2025-02-25_18-16-34' in 0.0060s.\n",
      "\u001b[36m(_train_tune pid=516706)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "[rank: 0] Seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=104.0]        \n",
      "Epoch 995: 100%|██████████| 1/1 [00:00<00:00, 72.89it/s, v_num=2587929, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=104.0]\n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=2587929, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=104.0]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 74.06it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0556, valid_loss=104.0]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.27it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 35.30it/s, v_num=2587929, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=85.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MAE           | 0      | eval \n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "4 | context_adapter | Linear        | 8.0 K  | train\n",
      "5 | mlp_decoder     | MLP           | 2.4 K  | train\n",
      "----------------------------------------------------------\n",
      "494 K     Trainable params\n",
      "0         Non-trainable params\n",
      "494 K     Total params\n",
      "1.978     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "1         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096fdb8436ba41058dd1ef06d31cb85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoLSTM"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batch Size Exploration\n",
    "config = dict(batch_size = tune.choice([8, 16, 32, 64]), encoder_hidden_size = 200, encoder_n_layers = 2, context_size = 10, decoder_hidden_size = 200, learning_rate = 0.001, max_steps = 1000, input_size = -1, inference_input_size = -1)\n",
    "LSTMmodel = AutoLSTM(h = 4, backend = \"ray\", config = config)\n",
    "LSTMmodel.fit(dataset = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72525a99-c896-4faa-be81-62b74f65da48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8388232-05f0-4a2a-9c70-19eab8ae5136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a5e5f4-de59-40ed-96aa-3293f072d98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
